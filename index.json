
[{"content":"等风来，不如追风去。\n","date":"3 June 2025","externalUrl":null,"permalink":"/","section":"","summary":"","title":"","type":"page"},{"content":"","date":"3 June 2025","externalUrl":null,"permalink":"/years/2024/","section":"Years","summary":"","title":"2024","type":"years"},{"content":"","date":"3 June 2025","externalUrl":null,"permalink":"/conferences/","section":"Conferences","summary":"","title":"Conferences","type":"conferences"},{"content":" 简单记录一下本文的一些tricks\n冻结教师 # 相当于全部微调，冻结教师的特征提取部分可以使其具有更强的泛化性。过强、过于专注某个知识的教师会给学生提供过于集中的知识，不利于蒸馏。\n实证观察（图1）表明，随着教师模型规模的增加，教师和学生之间的差异变得更为显著，从而限制了KD的有效性。\n作者采用一种互信息的方法证明该点，如图4所示。 $$ H(F) = I(X; F) + I(Y; F) + Z $$\n( F )：老师模型中某一层提取的特征（feature representation） ( X )：输入图片 ( Y )：目标检测任务的标签（ground-truth target） ( I(X;F) )：特征F里包含了多少关于输入图片X的信息，体现泛化性，用特征反向重建图片的效果（如U-Net解码，重建loss越低说明特征保留了更多输入信息） ( I(Y;F) )：特征F里包含了多少关于任务目标Y的信息，体现对检测任务的适应性，用mAP（平均精度）衡量，越高说明特征对目标检测越有用 ( Z )：无关噪声（nuisance），跟任务无关的信息 Query蒸馏 # Query Distillation包括两个部分：\nQuery Position Distill（QPD）：让学生学会老师的object queries定位（box）的空间分布。 Query Relation Distill（QRD）：让学生学会老师object queries之间的关系（自注意力/相关性）。 Query对齐（一对一匹配） # 要比较老师和学生每一个object query，需要建立对应关系。DETR模型是端到端的，每个预测query没有预定义顺序，所以要用匈牙利匹配（Hungarian Matching）进行一对一配对。\n$$ y_{t,i}^{(l)} = f_t^{(l)}(x;i),\\quad i\\in{\\text{CLS}}\\cup P, $$\n$$ \\hat{\\sigma} = \\arg\\min_{\\sigma \\in \\mathfrak{S}N} \\sum{i=1}^{N} \\mathcal{L}_{match}\\big(q^{(t)}i, q^{(s)}{\\sigma(i)}\\big) $$\n$N$：query的个数（比如900） $q^{(t)}_i$：第i个老师query $q^{(s)}_j$：第j个学生query $\\sigma$：排列（permutation），表示学生query与老师query的最佳配对方式 $\\mathcal{L}_{match}$：定义每对query的匹配损失 匹配损失定义： # $$ L_{\\text{match}}(q^{(t)}, q^{(s)}) = \\alpha_1 L_{\\text{KL}}(p^{(t)}, p^{(s)}) + \\alpha_2 L_{\\text{L1}}(b^{(t)}, b^{(s)}) + \\alpha_3 L_{\\text{GIoU}}(b^{(t)}, b^{(s)}) $$\n$p$：类别概率（分类分布） $b$：边界框 $[x, y, w, h]$ $\\mathcal{L}_{KL}$：KL散度（衡量分类分布的差异） $\\mathcal{L}_{L1}$：L1回归损失（预测框与GT框） $\\mathcal{L}_{GIoU}$：GIoU损失（常用于目标检测的边界框损失） $\\alpha_1, \\alpha_2, \\alpha_3$：加权系数，文中经验设置为2, 5, 2 通过匈牙利算法，老师和学生每一对object query都一一对应，可以直接做知识迁移。\nQuery Position Distill（QPD）——位置知识蒸馏 # $$ L_{\\text{QPD}} = \\sum_{i=1}^{N} \\left[ \\beta_1 L_{\\text{L1}}(b_i^t, b_{\\sigma(i)}^s) + \\beta_2 L_{\\text{GIoU}}(b_i^t, b_{\\sigma(i)}^s) \\right] $$\n$b^{(t)}_i$：老师第i个query的预测框 $b^{(s)}_{\\sigma(i)}$：匹配到的学生query的预测框 $\\beta_1, \\beta_2$：经验设置为5, 2 不光让学生预测类别分布像老师，更要让框的位置分布、空间特性也像老师。这弥补了DETR模型训练时，只有很少的query参与位置回归监督（如每张图只有7个目标，900个query，大部分没监督）。 Query Relation Distill（QRD）——关系知识蒸馏 # $$ L_{\\text{QRD}} = \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\left| A^t_{i,j} - A^s_{\\sigma(i),\\sigma(j)} \\right| $$\n$A^{(t)}$：老师query的自注意力（self-attention）权重矩阵，$N \\times N$ $A^{(s)}$：学生query的自注意力权重矩阵 $|\\cdot|$：L1损失 DETR模型里，每个object query通过自注意力与其它query建立联系，这些关系决定了模型对复杂场景的解析。让学生模仿老师的attention关系，更容易学到场景中的目标间互动、抑制等“高阶信息”。 总体损失函数： # $$ L_{\\text{overall}} = \\gamma_1 L_{\\text{task}} + \\gamma_2 L_{\\text{QPD}} + \\gamma_3 L_{\\text{QRD}} $$\n$\\mathcal{L}_{task}$：原本的目标检测损失（如分类、回归、GIoU等） $\\gamma_1, \\gamma_2, \\gamma_3$：加权系数，文中经验设置为1, 2, 1 ","date":"3 June 2025","externalUrl":null,"permalink":"/paperreading/eccv/dlim-det/dlim-det/","section":"Paper Reading","summary":"","title":"Distilling Knowledge from Large-Scale Image Models for Object Detection","type":"paperreading"},{"content":"","date":"3 June 2025","externalUrl":null,"permalink":"/conferences/eccv/","section":"Conferences","summary":"","title":"ECCV","type":"conferences"},{"content":"","date":"3 June 2025","externalUrl":null,"permalink":"/paperreading/eccv/","section":"Paper Reading","summary":"","title":"ECCV","type":"paperreading"},{"content":"","date":"3 June 2025","externalUrl":null,"permalink":"/tags/knowledge-distillation/","section":"Tags","summary":"","title":"Knowledge Distillation","type":"tags"},{"content":"","date":"3 June 2025","externalUrl":null,"permalink":"/paperreading/","section":"Paper Reading","summary":"","title":"Paper Reading","type":"paperreading"},{"content":"","date":"3 June 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"3 June 2025","externalUrl":null,"permalink":"/years/","section":"Years","summary":"","title":"Years","type":"years"},{"content":" 本文可以说是对知识蒸馏各种Tricks的一次尝试，将各种有用的Trick结合起来，提出了一个新的蒸馏方法，为UNIC。\n论文中对实际采用的方法进行的描述比较笼统，并没有具体深入去讲解如何操作与实现，但它给的开源代码是真的特别特别好，结构清晰、命名规范，没有堆砌任何多余代码。\n动机 # 不同预训练策略（如自监督学习 (Self‑Supervised Learning)、监督学习 (Supervised Learning)、掩码建模 (Masked Modeling)）往往在不同场景中各有所长。例如，DINO 在迁移学习上表现优异，而 DeiT‑III 在 ImageNet 分类上达到最优。\n本文的出发点是：如何将这些互补优势融合，得到一个通用编码器 (Universal Encoder)，以单一模型同时在图像分类、细粒度识别、语义分割、深度估计等任务中取得或超越各自最好教师 (Teacher) 的性能，\n主要贡献 # 多教师蒸馏 (Multi‑Teacher Distillation) 框架 以 ViT‑Base 为骨干，蒸馏来自多个教师模型的特征表示，不依赖任何监督标签，仅用余弦损失 (Cosine Loss) 与平滑 L₁ 损失 (Smooth‑L₁ Loss)。 特征标准化 (Feature Standardization) 对各教师输出特征做零均值、单位方差标准化，以消除 CLS Token 与 Patch Token 及不同教师间的统计差异。 CLS / Patch 专用投影头 (Dedicated Projectors) 分别为全局 CLS Token 与局部 Patch Token 设计教师专属 MLP 投影头 (Projector)，增强对两类特征的适配。 可扩展投影器阶梯 (Ladder of Projectors) 在学生模型每个中间层附加轻量级 MLP，将所有中间层特征汇聚 (sum) 到对应教师的投影头，更多层次信息更直接地参与蒸馏。 教师丢弃正则 (Teacher Dropping Regularization) 利用各教师当前损失大小动态随机丢弃 (drop) 部分教师的损失，仅保留最大损失教师，平衡学习进度，避免性能倾斜。 具体实现 # 多教师蒸馏基础框架 # 输入与输出表示 # 设有 $M$ 位教师模型 $\\mathcal{T}={T_1,\\dots,T_M}$，皆为 ViT‑Base 编码器。对于输入图像 $x$，教师 $T_t$ 在第 $l$ 层输出一组 $d$ 维特征向量 $$ y_{t,i}^{(l)} = f_t^{(l)}(x;i),\\quad i\\in{\\text{CLS}}\\cup P, $$ 其中 CLS 表示全局分类 Token，$P$ 为 $H\\times W$ 个局部 Patch Token。最终只取 $l=L$（最后一层）的输出 $y_{t,i}$ 作为蒸馏目标。 学生网络与可剔除投影头 # 学生模型 $S$ 同样为 ViT‑Base，输出对应特征 $$ z_i = f_s(x;,i),\\quad i\\in{\\text{CLS}}\\cup P. $$\n为每位教师 $t$ 追加可剔除 (expendable) 投影头 $h_t(\\cdot)$，将 $d$ 维 $z_i$ 映射至教师特征空间。投影头均为含 GeLU 激活的两层 MLP\n训练结束后去除所有 $h_t$，仅保留学生编码器。\n损失函数定义 # 对每位教师 $t$、每个 Token $i$（CLS 或 Patch）定义蒸馏损失： $$ L_t(x,i)=0.5\\Bigl[ L_{\\cos}\\bigl(h_t(z_i),y_{t,i}\\bigr) +L_{\\mathrm{smooth}\\text{-}1}\\bigl(h_t(z_i),y_{t,i}\\bigr) \\Bigr] $$ 其中 $$ L_{\\cos}(s,t)=1-\\frac{s^\\top t}{|s|_2,|t|*2} $$\n$$ L_{\\mathrm{smooth}\\text{-}1}(s,t) = \\begin{cases} 0.5, |s - t|_2^2, \u0026amp; \\text{if } |s - t|_1 \u0026lt; 1 \\\\ |s - t|_1 - 0.5, \u0026amp; \\text{otherwise} \\end{cases} $$\n总损失 汇总所有教师与所有 Token： $$ L(x) =\\sum_{t=1}^M\\Bigl[L_t(x,\\text{CLS})+\\tfrac{1}{|P|}\\sum_{p\\in P}L_t(x,p)\\Bigr] $$\n特征标准化 # 动机：不同教师及 CLS/Patch Token 的一阶、二阶统计量（均值、方差）差异显著，会导致某些教师/Token 的损失主导蒸馏过程，缓慢或偏向地学习其它教师特征。 实现：对教师特征 $y_{t,i}$ 按通道维度做零均值、单位方差标准化： $$ \\tilde y_{t,i} ;=;\\frac{y_{t,i}-\\mu_t}{\\sigma_t} $$ 其中 $\\mu_t,\\sigma_t$ 通过指数移动平均 (EMA) 在线估计： $$ \\mu_t\\leftarrow m\\mu_t+(1-m)\\overline{y}_{t},\\quad \\sigma_t^2\\leftarrow m\\sigma_t^2+(1-m)\\mathrm{Var}(y_t) $$ 标准化后再计算蒸馏损失，有效消除教师间及 Token 间的量纲不一致，全面提升分类与密集预测表现。 CLS/Patch 专用投影头 # 全局 CLS Token 应侧重图像级语义，局部 Patch Token 则聚焦空间细节。为此，为 CLS 和 Patch 分别各自学习一对 $h_t^{\\text{CLS}}$、$h_t^{\\text{Patch}}$ ——两组参数互不共享，却对最终蒸馏策略零额外开销（训练后剔除）。\n可扩展投影器阶梯 (Ladder of Projectors) # 动机：中间层往往包含丰富的多尺度特征，直接在此加损失会带来超参爆炸式增长与优化困难。 结构：在学生每层第 $l$ (1≤l≤L) 输出 $z^{(l)}$ 附加轻量 MLP $h^{(l)}t$，并将所有层级输出汇聚到教师 $t$ 的主投影头： $$ h_t^{\\mathrm{LP}}\\bigl({z^{(l)}}\\bigr) ;=;\\sum{l=1}^L h^{(l)}_t\\bigl(z^{(l)}\\bigr) $$ 其中对 $l\u0026lt;L$ 的中间层 MLP 隐藏维度 $d_h^{(l)}$ 可设置为 $d$ 或更小（实验中取 768），仅在最后一层保留完整 $4d$ 隐藏维度，以控制参数规模。 效果：大幅提升 Patch Token 在密集任务上的判别力，且对图像分类亦有 +0.5% 的增益。 教师丢弃正则 (Teacher Dropping) # ","date":"22 April 2025","externalUrl":null,"permalink":"/paperreading/eccv/unic/unic/","section":"Paper Reading","summary":"","title":"UNIC: Universal Classiﬁcation Models via Multi-teacher Distillation","type":"paperreading"},{"content":"","date":"21 April 2025","externalUrl":null,"permalink":"/tags/loss/","section":"Tags","summary":"","title":"Loss","type":"tags"},{"content":" 记录一下人脸识别方面的Margin Loss，该loss通过对特征增加margin来增强模型的区分性。\n主要思想是通过对特征进行margin调整来增强模型的区分性。具体来说，Margin Loss在计算损失时，会对正样本和负样本之间的距离进行调整，使得正样本之间的距离更小，而负样本之间的距离更大。这样可以有效地提高模型对不同类别之间的区分能力。或许可以借鉴到医学影像分级中。\nSoftmax 损失 # Softmax 函数（Softmax）\n对于网络输出的 logits 向量 $\\mathbf{z} = [z_1, z_2, \\dots, z_n]$，Softmax 将其转为概率分布：\n$$ p_j = \\frac{e^{z_j}}{\\sum_{k=1}^n e^{z_k}} $$\n交叉熵损失（Cross-Entropy Loss）\n给定样本的真实标签为 $y$，Softmax + 交叉熵定义为：\n$$ L_{\\text{CE}} = -\\log p_{y} = -\\log \\frac{e^{z_{y}}}{\\sum_{k=1}^n e^{z_k}} $$ 通常我们在最后一层将 $z_j = \\mathbf{w}_j^\\top \\mathbf{x} + b_j$，其中 $\\mathbf{x}$ 是归一化前的特征向量，$\\mathbf{w}_j$ 是第 $j$ 类的权重向量。\n局限性\n类内紧凑度不足：无法明确拉近同类样本的特征距离。 类间可分性弱：不同类别的决策边界只由 logits 大小决定，难以保证边界具有足够的\u0026quot;安全间隔\u0026quot;（margin）。 Margin Softmax 损失 # 通用公式 # 许多变体可统一为：\n$$ L = -\\frac{1}{N}\\sum_{i=1}^N \\log\\frac{ e^{s\\bigl(\\cos(\\theta_{y_i})\\cdot m_1 + m_2\\bigl)-m_3} }{ e^{s\\bigl(\\cos(\\theta_{y_i})\\cdot m_1 + m_2\\bigl)-m_3} +\\sum_{j \\ne y_i} e^{s\\cos(\\theta_j)} } $$\n$\\theta_j$：样本特征 $\\mathbf{x}_i$ 与类别中心 $\\mathbf{w}_j$ 的夹角，$\\cos\\theta_j = \\frac{\\mathbf{w}_j^\\top \\mathbf{x}_i}{|\\mathbf{w}_j||\\mathbf{x}_i|}$,此处是设置偏置$b_j$为0。 $s$：缩放因子（scale），提高数值稳定性。 $m_1,m_2,m_3$：不同方法中采用的 乘性／加性 margin 参数。 SphereFace # 参数：\n$$ m_1 = 4,\\quad m_2 = 0,\\quad m_3 = 0 $$\n损失公式：\n$$ L = -\\frac{1}{N}\\sum_i \\log\\frac{e^{s\\cos(m\\theta_{y_i})}} {e^{s\\cos(m\\theta_{y_i})} + \\sum_{j\\ne y_i} e^{s\\cos(\\theta_j)}} $$\n特点：\n将角度 $\\theta$ 乘以因子 $m$，等同在角度空间拉开类间距离。 在对角度的非线性变换下，样本与中心的\u0026quot;角度\u0026quot;更加分散。 优缺点：\n优点：几何意义清晰，能显著提高判别力。 缺点：对 $m$ 敏感，训练收敛困难，需要精心初始化和学习率调度。 CosFace # 参数：\n$$ m_1 = 1,\\quad m_2 = 0,\\quad m_3 = 0.35 $$ 损失公式：\n$$ L = -\\frac{1}{N}\\sum_i \\log\\frac{e^{s\\bigl(\\cos\\theta_{y_i} - m\\bigr)}} {e^{s\\bigl(\\cos\\theta_{y_i} - m\\bigr)} + \\sum_{j\\ne y_i} e^{s\\cos(\\theta_j)}} $$ 特点： 直接在余弦相似度上减去固定 margin $m$，易于理解和实现。 不改变角度，只在概率空间人为拉开决策边界。 优缺点： 优点：训练稳定、超参数调节相对简单。 缺点：相比 ArcFace 可解释性稍弱，但在实践中效果同样优秀。 ArcFace # 参数：\n$$ m_1 = 1,\\quad m_2 = 0.5,\\quad m_3 = 0 $$\n损失公式：\n$$ L = -\\frac{1}{N}\\sum_i \\log\\frac{e^{s\\cos(\\theta_{y_i} + m)}} {e^{s\\cos(\\theta_{y_i} + m)} + \\sum_{j\\ne y_i} e^{s\\cos(\\theta_j)}} $$\n特点：\n在角度上加一个固定 margin，再计算余弦。 兼具几何直观性与训练稳定性，已成为人脸识别领域的 事实标准。 优缺点：\n优点：可解释性强、收敛快、效果稳定。 缺点：需要对 $m$ 和 $s$ 进行合理调参，但经验值已较成熟（$m\\approx0.5, s\\approx64$） 区别 # 特性 SphereFace CosFace ArcFace Margin 形式 乘性角度：$\\cos(m\\theta)$ 加性余弦：$cos\\theta - m$ 加性角度：$cos(\\theta + m)$ 几何解释 在角度空间非线性拉伸 在相似度空间平移 在角度空间平移 收敛难度 较高（需特殊优化技巧） 低（易于实现） 中等（已被大量实践验证） 超参数敏感度 (m) 敏感，对初始化和学习率要求高 (m) 影响平滑，但较稳 (m,s) 有经验值，可快速调优 实际效果 有时优于 ArcFace（需精调） 与 ArcFace 相当，训练更稳定 最主流、综合表现最佳 核心差异在于 margin 作用的位置： SphereFace 对角度做了乘性变换，增加非线性难度； CosFace 在余弦相似度上减去常数，更易控制； ArcFace 在角度上加常数，同时保留了几何直观性和训练稳定性。 总结 # 传统 Softmax 只能拉开 logits 大小，无法显式构造“安全间隔”。 Margin-based Softmax 通过对角度或余弦值引入 margin，提高类间可分性。 三种主流方法的区别在于 margin 的乘性／加性及作用空间（角度 vs 余弦），实际中 ArcFace 最为常用。 ","date":"21 April 2025","externalUrl":null,"permalink":"/paperreading/others/margin-loss/marginloss/","section":"Paper Reading","summary":"","title":"Margin Loss","type":"paperreading"},{"content":"","date":"21 April 2025","externalUrl":null,"permalink":"/paperreading/others/","section":"Paper Reading","summary":"","title":"Others","type":"paperreading"},{"content":"","date":"12 November 2024","externalUrl":null,"permalink":"/python/tricks/","section":"Python","summary":"","title":"Cheet Sheets","type":"python"},{"content":"","date":"12 November 2024","externalUrl":null,"permalink":"/tags/lightweight/","section":"Tags","summary":"","title":"LightWeight","type":"tags"},{"content":"","date":"12 November 2024","externalUrl":null,"permalink":"/python/","section":"Python","summary":"","title":"Python","type":"python"},{"content":"","date":"12 November 2024","externalUrl":null,"permalink":"/tags/trainstrategy/","section":"Tags","summary":"","title":"TrainStrategy","type":"tags"},{"content":" 模型搭建 # 参考MobileNetV2的搭建方法\n去掉ReLU，改为ReLU6\nV2 传递的思想只有一个，即ReLU 会对 channel 数较低的张量造成较大的信息损耗，简单来说，就是当低维信息映射到高维，经过ReLU后再映射回低维时，若映射到的维度相对较高，则信息变换回去的损失较小；若映射到的维度相对较低，则信息变换回去后损失很大，如下图所示：\n当原始输入维度数增加到 15 以后再加 ReLU，基本不会丢失太多的信息；但如果只把原始输入维度增加到 2~5维度后再加 ReLU，则会出现较为严重的信息丢失。因此，认为对低维度做ReLU运算，很容易造成信息的丢失。而在高维度进行ReLU运算的话，信息的丢失则会很少。另外一种解释是，高维信息变换回低维度信息时，相当于做了一次特征压缩，会损失一部分信息，而再进行过ReLU后，损失的部分就更大了。作者为了这个问题，就将ReLU替换成线性激活函数。\n使用Inverted Residuals和Linear Bottlenecks\n这个模块是为了解决一开始提出的那个低维-高维-低维的问题，即将最后一层的ReLU替换成线性激活函数，而其它层的激活函数依然是ReLU6。\n也可以参考其网络架构，如下图\n训练 # 可以参考GhostNetV3\n","date":"12 November 2024","externalUrl":null,"permalink":"/python/tricks/%E5%B0%8F%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5/lw/","section":"Python","summary":"","title":"小模型的搭建和训练tricks","type":"python"},{"content":"病理学图像和基因组的多模态分类的一篇文章,图画的还是挺清晰易懂的,不过文章我也没有细看,主要看了两个模块:\n一个模态交互\n一个在线数据生成 模态交互如下图所示,使用病理学图生成Q,基因生成K,V各自为各自的,使用Q和K交互得到的注意力图去和各自的V做点积,从而使得两种数据可以对齐(我是这样子理解的,其实也可以理解为CLIP,但没有CLIP那么明显的对齐)\n在线数据生成如下图所示,和Mixup类似,将两个或多个输入进行拼接从而得到新的输入,从而就行了数据扩增.\n但作者先利用注意力分数和topk算法对特征进行了筛选(不重要的特征不需要再扩增了,越多越难学),将不重要的特征加权融合,重要的特征进行拼接融合.\n采用余弦相似度对特征进行选择,选择与自己最相似的特征进行融合\n融合后还需要与原来筛选下的重要特征进行fusing(就是简单的contact,因为原始特征中存在重要的信息)\n","date":"11 November 2024","externalUrl":null,"permalink":"/paperreading/tmi/mcfn/","section":"Paper Reading","summary":"","title":"Multimodal Co-Attention Fusion Network With  Online Data Augmentation for Cancer  Subtype Classification","type":"paperreading"},{"content":"","date":"11 November 2024","externalUrl":null,"permalink":"/conferences/tmi/","section":"Conferences","summary":"","title":"TMI","type":"conferences"},{"content":"","date":"11 November 2024","externalUrl":null,"permalink":"/paperreading/tmi/","section":"Paper Reading","summary":"","title":"TMI","type":"paperreading"},{"content":"","date":"11 November 2024","externalUrl":null,"permalink":"/tags/vit/","section":"Tags","summary":"","title":"ViT","type":"tags"},{"content":"","date":"11 November 2024","externalUrl":null,"permalink":"/tags/attention/","section":"Tags","summary":"","title":"Attention","type":"tags"},{"content":"","date":"11 November 2024","externalUrl":null,"permalink":"/tags/segmentation/","section":"Tags","summary":"","title":"Segmentation","type":"tags"},{"content":"关于3D医学影像分割的文章，主要就是提出了一个成对注意力模块(efficient paired-attention，EPA) EPA块可以提取空间和通道信息，并且Q和K的权重是共享的。\n直接看公式和代码就可以\nclass EPA(nn.Module): \u0026#34;\u0026#34;\u0026#34; Efficient Paired Attention Block, based on: \u0026#34;Shaker et al., UNETR++: Delving into Efficient and Accurate 3D Medical Image Segmentation\u0026#34; \u0026#34;\u0026#34;\u0026#34; def __init__(self, input_size, hidden_size, proj_size, num_heads=4, qkv_bias=False, channel_attn_drop=0.1, spatial_attn_drop=0.1): super().__init__() self.num_heads = num_heads self.temperature = nn.Parameter(torch.ones(num_heads, 1, 1)) self.temperature2 = nn.Parameter(torch.ones(num_heads, 1, 1)) # qkvv are 4 linear layers (query_shared, key_shared, value_spatial, value_channel) self.qkvv = nn.Linear(hidden_size, hidden_size * 4, bias=qkv_bias) # E and F are projection matrices used in spatial attention module to project keys and values from HWD-dimension to P-dimension self.E = nn.Linear(input_size, proj_size) self.F = nn.Linear(input_size, proj_size) self.attn_drop = nn.Dropout(channel_attn_drop) self.attn_drop_2 = nn.Dropout(spatial_attn_drop) self.out_proj = nn.Linear(hidden_size, int(hidden_size // 2)) self.out_proj2 = nn.Linear(hidden_size, int(hidden_size // 2)) def forward(self, x): B, N, C = x.shape #print(\u0026#34;The shape in EPA \u0026#34;, self.E.shape) qkvv = self.qkvv(x).reshape(B, N, 4, self.num_heads, C // self.num_heads) qkvv = qkvv.permute(2, 0, 3, 1, 4) q_shared, k_shared, v_CA, v_SA = qkvv[0], qkvv[1], qkvv[2], qkvv[3] q_shared = q_shared.transpose(-2, -1) k_shared = k_shared.transpose(-2, -1) v_CA = v_CA.transpose(-2, -1) v_SA = v_SA.transpose(-2, -1) k_shared_projected = self.E(k_shared) v_SA_projected = self.F(v_SA) q_shared = torch.nn.functional.normalize(q_shared, dim=-1) k_shared = torch.nn.functional.normalize(k_shared, dim=-1) attn_CA = (q_shared @ k_shared.transpose(-2, -1)) * self.temperature attn_CA = attn_CA.softmax(dim=-1) attn_CA = self.attn_drop(attn_CA) x_CA = (attn_CA @ v_CA).permute(0, 3, 1, 2).reshape(B, N, C) attn_SA = (q_shared.permute(0, 1, 3, 2) @ k_shared_projected) * self.temperature2 attn_SA = attn_SA.softmax(dim=-1) attn_SA = self.attn_drop_2(attn_SA) x_SA = (attn_SA @ v_SA_projected.transpose(-2, -1)).permute(0, 3, 1, 2).reshape(B, N, C) # Concat fusion x_SA = self.out_proj(x_SA) x_CA = self.out_proj2(x_CA) x = torch.cat((x_SA, x_CA), dim=-1) return x ","date":"11 November 2024","externalUrl":null,"permalink":"/paperreading/tmi/uneter_pp/","section":"Paper Reading","summary":"","title":"UNETR++: Delving Into Efficient and Accurate  3D Medical Image Segmentation","type":"paperreading"},{"content":"图像恢复的一篇文章，也是想要减少特征中存在的大量冗余，如下图所示，不需要在全部的token上做运算，可以通过一些筛选去除不重要的注意力。 可以分成两部分：\nASSA，对通过relu对softmax得到的特征分数进行筛选，从而相当于通过hard滤波器去掉一部分特征。此外，作者通过可反向传播更新的参数$w_1$和$w_2$进行两者的控制. FRFN，使用了FasterNet中的Pconv先降低一部分通道冗余，然后将特征图按通道分成两个部分，一部分通过深度卷积得到新特征，一部分直接与其相乘（其实没啥道理，可以看成某种注意力） 代码如下所示:\nclass WindowAttention_sparse(nn.Module): def __init__(self, dim, win_size,num_heads, token_projection=\u0026#39;linear\u0026#39;, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.): super().__init__() self.dim = dim self.win_size = win_size # Wh, Ww self.num_heads = num_heads head_dim = dim // num_heads self.scale = qk_scale or head_dim ** -0.5 # define a parameter table of relative position bias self.relative_position_bias_table = nn.Parameter( torch.zeros((2 * win_size[0] - 1) * (2 * win_size[1] - 1), num_heads)) # 2*Wh-1 * 2*Ww-1, nH # get pair-wise relative position index for each token inside the window coords_h = torch.arange(self.win_size[0]) # [0,...,Wh-1] coords_w = torch.arange(self.win_size[1]) # [0,...,Ww-1] coords = torch.stack(torch.meshgrid([coords_h, coords_w])) # 2, Wh, Ww coords_flatten = torch.flatten(coords, 1) # 2, Wh*Ww relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :] # 2, Wh*Ww, Wh*Ww relative_coords = relative_coords.permute(1, 2, 0).contiguous() # Wh*Ww, Wh*Ww, 2 relative_coords[:, :, 0] += self.win_size[0] - 1 # shift to start from 0 relative_coords[:, :, 1] += self.win_size[1] - 1 relative_coords[:, :, 0] *= 2 * self.win_size[1] - 1 relative_position_index = relative_coords.sum(-1) # Wh*Ww, Wh*Ww self.register_buffer(\u0026#34;relative_position_index\u0026#34;, relative_position_index) trunc_normal_(self.relative_position_bias_table, std=.02) if token_projection ==\u0026#39;linear\u0026#39;: self.qkv = LinearProjection(dim,num_heads,dim//num_heads,bias=qkv_bias) else: raise Exception(\u0026#34;Projection error!\u0026#34;) self.token_projection = token_projection self.attn_drop = nn.Dropout(attn_drop) self.proj = nn.Linear(dim, dim) self.proj_drop = nn.Dropout(proj_drop) self.softmax = nn.Softmax(dim=-1) self.relu = nn.ReLU() self.w = nn.Parameter(torch.ones(2)) def forward(self, x, attn_kv=None, mask=None): B_, N, C = x.shape q, k, v = self.qkv(x,attn_kv) q = q * self.scale attn = (q @ k.transpose(-2, -1)) relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view( self.win_size[0] * self.win_size[1], self.win_size[0] * self.win_size[1], -1) # Wh*Ww,Wh*Ww,nH relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous() # nH, Wh*Ww, Wh*Ww ratio = attn.size(-1)//relative_position_bias.size(-1) relative_position_bias = repeat(relative_position_bias, \u0026#39;nH l c -\u0026gt; nH l (c d)\u0026#39;, d = ratio) attn = attn + relative_position_bias.unsqueeze(0) if mask is not None: nW = mask.shape[0] mask = repeat(mask, \u0026#39;nW m n -\u0026gt; nW m (n d)\u0026#39;,d = ratio) attn = attn.view(B_ // nW, nW, self.num_heads, N, N*ratio) + mask.unsqueeze(1).unsqueeze(0) attn = attn.view(-1, self.num_heads, N, N*ratio) attn0 = self.softmax(attn) attn1 = self.relu(attn)**2#b,h,w,c else: attn0 = self.softmax(attn) attn1 = self.relu(attn)**2 w1 = torch.exp(self.w[0]) / torch.sum(torch.exp(self.w)) w2 = torch.exp(self.w[1]) / torch.sum(torch.exp(self.w)) attn = attn0*w1+attn1*w2 attn = self.attn_drop(attn) x = (attn @ v).transpose(1, 2).reshape(B_, N, C) x = self.proj(x) x = self.proj_drop(x) return x class FRFN(nn.Module): def __init__(self, dim=32, hidden_dim=128, act_layer=nn.GELU,drop = 0., use_eca=False): super().__init__() self.linear1 = nn.Sequential(nn.Linear(dim, hidden_dim*2), act_layer()) self.dwconv = nn.Sequential(nn.Conv2d(hidden_dim,hidden_dim,groups=hidden_dim,kernel_size=3,stride=1,padding=1), act_layer()) self.linear2 = nn.Sequential(nn.Linear(hidden_dim, dim)) self.dim = dim self.hidden_dim = hidden_dim self.dim_conv = self.dim // 4 self.dim_untouched = self.dim - self.dim_conv self.partial_conv3 = nn.Conv2d(self.dim_conv, self.dim_conv, 3, 1, 1, bias=False) def forward(self, x): # bs x hw x c bs, hw, c = x.size() hh = int(math.sqrt(hw)) # spatial restore x = rearrange(x, \u0026#39; b (h w) (c) -\u0026gt; b c h w \u0026#39;, h = hh, w = hh) x1, x2,= torch.split(x, [self.dim_conv,self.dim_untouched], dim=1) x1 = self.partial_conv3(x1) x = torch.cat((x1, x2), 1) # flaten x = rearrange(x, \u0026#39; b c h w -\u0026gt; b (h w) c\u0026#39;, h = hh, w = hh) x = self.linear1(x) #gate mechanism x_1,x_2 = x.chunk(2,dim=-1) x_1 = rearrange(x_1, \u0026#39; b (h w) (c) -\u0026gt; b c h w \u0026#39;, h = hh, w = hh) x_1 = self.dwconv(x_1) x_1 = rearrange(x_1, \u0026#39; b c h w -\u0026gt; b (h w) c\u0026#39;, h = hh, w = hh) x = x_1 * x_2 x = self.linear2(x) # x = self.eca(x) return x ","date":"4 November 2024","externalUrl":null,"permalink":"/paperreading/cvpr/ast/","section":"Paper Reading","summary":"","title":"Adapt or Perish: Adaptive Sparse Transformer with Attentive Feature  Refinement for Image Restoration","type":"paperreading"},{"content":"","date":"4 November 2024","externalUrl":null,"permalink":"/conferences/cvpr/","section":"Conferences","summary":"","title":"CVPR","type":"conferences"},{"content":"","date":"4 November 2024","externalUrl":null,"permalink":"/paperreading/cvpr/","section":"Paper Reading","summary":"","title":"CVPR","type":"paperreading"},{"content":"relu、relu6、sigmoid、h_sigmoid、swish、h_swish的公式和图像如下图所示，h为hard的意思，是其对应的简化版本，用于加速计算（去掉了指数运算）。\n","date":"20 October 2024","externalUrl":null,"permalink":"/python/tricks/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/act/","section":"Python","summary":"","title":"常见激活函数","type":"python"},{"content":"","date":"20 October 2024","externalUrl":null,"permalink":"/years/2019/","section":"Years","summary":"","title":"2019","type":"years"},{"content":"","date":"20 October 2024","externalUrl":null,"permalink":"/tags/cnn/","section":"Tags","summary":"","title":"CNN","type":"tags"},{"content":" 作者认为：不仅自然世界中的图像存在高低频，卷积层的输出特征图以及输入通道（feature maps or channels）也都存在高、低频分量。 低频分量支撑的是整体，比如企鹅的白色大肚皮。显然，低频分量是存在冗余的，在编码过程中可以节省。\n基于以上考虑，作者提出OctConv用以取代传统CNN（vanilla CNN）。有以下两个关键步骤：\n第一步，我们要获得输入通道（或图像）的线性尺度表示，称为Octave feature representation。\n所谓高频分量，是指不经过高斯滤波的原始通道（或图像）；所谓低频分量，是指经过t=2的高斯滤波得到的通道（或图像）。\n由于低频分量是冗余的，因此作者将低频分量的通道长/ 宽设置为高频分量通道长/ 宽的一半。 在音乐中，Octave是八音阶的意思，隔一个八音阶，频率会减半；在这里，drop an octave就是通道尺寸减半的含义。\n那么高频通道和低频通道比例是多少呢？作者设置了一个超参数α∈[0,1]，表示低频通道的比例。\n在本文中，输入通道低频比例αin和输出通道低频比例αout设为相同。\n图：企鹅白肚皮（低频）冗余（上）；传统CNN，OctConv对比（下）。\n问题来了：由于高 / 低频通道尺寸不一致，因此传统卷积无法执行。\n但我们又不能简单地对低频通道进行下采样，因为这样不就白干了吗，计算量和内存就没办法节省了。\n因此我们有第二步：\n第二步，作者提出了对应的卷积解决方案：Octave Convolution。\n首先给一些定义：\n设卷积输入的高频和低频部分分别是 $X^H$ 和 $X^L$，卷积输出的低频分量和高频分量分别是 $Y^L$ 和 $Y^H$。卷积操作中，$W^H$ 负责构建 $Y^H$，$W^L$ 负责构建 $Y^L$。\n我们将：\n$W^H$ 取负责从 $X^H$ 到 $Y^H$ 的部分：$W^{H \\rightarrow H}$， 也有负责从 $X^L$ 到 $Y^H$ 的部分：$W^{L \\rightarrow H}$， 即 $W^H = [W^{H \\rightarrow H}, W^{L \\rightarrow H}]$。 其结构如下图右边所示。\n其中，$W^{H \\rightarrow H}$ 是传统卷积，因为输入、输出图像尺寸一样；对于 $W^{L \\rightarrow H}$ 部分，我们先对输入图像进行上采样（upsample），再执行传统卷积。这样，整体计算量仍然是节省的。\n$W^L$ 同理，但对 $W^{H \\rightarrow L}$ 执行的是降采样。 ","date":"20 October 2024","externalUrl":null,"permalink":"/paperreading/iccv/octave/","section":"Paper Reading","summary":"","title":"Drop an Octave: Reducing Spatial Redundancy in  Convolutional Neural Networks with Octave Convolution","type":"paperreading"},{"content":"","date":"20 October 2024","externalUrl":null,"permalink":"/conferences/iccv/","section":"Conferences","summary":"","title":"ICCV","type":"conferences"},{"content":"","date":"20 October 2024","externalUrl":null,"permalink":"/paperreading/iccv/","section":"Paper Reading","summary":"","title":"ICCV","type":"paperreading"},{"content":"","date":"18 October 2024","externalUrl":null,"permalink":"/years/2023/","section":"Years","summary":"","title":"2023","type":"years"},{"content":"和ghostnet很像的一篇文章，都在对卷积进行改进从而减少计算量。 不过ghostnet是使用cheap的操作去生成冗余特征图（冗余对网络分类很重要L），而本文则是觉得不同通道的特征图存在大量的相似，因此没必要对全部的特征图进行卷积。\n只需要对部分卷积执行深度卷积，剩余的卷积则直接contact过来，此时通道间没有交互，于是就紧跟两个1x1的卷积去进行通道交互和进一步的特征提取。\n但本文的baseline压的比较低，也被他人质疑过。\n方法是可以借鉴的，尤其是其中的PConv\n代码如下\nclass PConv2d(nn.Module): def __init__(self, in_channels, kernel_size = 3, n_div: int = 4, forward: str = \u0026#39;split_cat\u0026#39;): super(PConv2d, self).__init__() assert in_channels \u0026gt; 4, \u0026#34;in_channels should \u0026gt; 4, but got {} instead.\u0026#34;.format(in_channels) self.dim_conv = in_channels // n_div self.dim_untouched = in_channels - self.dim_conv self.conv = nn.Conv2d(in_channels=self.dim_conv, out_channels=self.dim_conv, kernel_size=kernel_size, stride=1, padding=(kernel_size - 1) // 2, bias=False) if forward == \u0026#39;slicing\u0026#39;: self.forward = self.forward_slicing elif forward == \u0026#39;split_cat\u0026#39;: self.forward = self.forward_split_cat else: raise NotImplementedError(\u0026#34;forward method: {} is not implemented.\u0026#34;.format(forward)) def forward_slicing(self, x: Tensor) -\u0026gt; Tensor: x[:, :self.dim_conv, :, :] = self.conv(x[:, :self.dim_conv, :, :]) return x def forward_split_cat(self, x: Tensor) -\u0026gt; Tensor: x1, x2 = torch.split(x, [self.dim_conv, self.dim_untouched], dim=1) x1 = self.conv(x1) x = torch.cat((x1, x2), dim=1) return x ","date":"18 October 2024","externalUrl":null,"permalink":"/paperreading/cvpr/fasternet/","section":"Paper Reading","summary":"","title":"Run, Don’t Walk: Chasing Higher FLOPS for Faster Neural Networks","type":"paperreading"},{"content":"","date":"16 October 2024","externalUrl":null,"permalink":"/years/2021/","section":"Years","summary":"","title":"2021","type":"years"},{"content":"常用的SENet将空间信息压缩成了1x1，这会导致位置信息被严重忽略并且网络的全局特征提取能力也比较有限，CBAM也是如此。因此作者就想要实现一个模块可以实现捕获远程空间信息依赖性的同时具有精确的位置信息。 方法其实很简单，就是沿着高度和宽度方向分别进行池化（和GhostNetV2的想法非常非常类似），然后进行Concat，从而获得全局信息。\n直接看代码就行\nclass h_sigmoid(nn.Module): def __init__(self, inplace=True): super(h_sigmoid, self).__init__() self.relu = nn.ReLU6(inplace=inplace) def forward(self, x): return self.relu(x + 3) / 6 class h_swish(nn.Module): def __init__(self, inplace=True): super(h_swish, self).__init__() self.sigmoid = h_sigmoid(inplace=inplace) def forward(self, x): return x * self.sigmoid(x) class CoordAtt(nn.Module): def __init__(self, inp, oup, reduction=32): super(CoordAtt, self).__init__() self.pool_h = nn.AdaptiveAvgPool2d((None, 1)) self.pool_w = nn.AdaptiveAvgPool2d((1, None)) mip = max(8, inp // reduction) self.conv1 = nn.Conv2d(inp, mip, kernel_size=1, stride=1, padding=0) self.bn1 = nn.BatchNorm2d(mip) self.act = h_swish() self.conv_h = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0) self.conv_w = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0) def forward(self, x): identity = x n,c,h,w = x.size() x_h = self.pool_h(x) x_w = self.pool_w(x).permute(0, 1, 3, 2) y = torch.cat([x_h, x_w], dim=2) y = self.conv1(y) y = self.bn1(y) y = self.act(y) x_h, x_w = torch.split(y, [h, w], dim=2) x_w = x_w.permute(0, 1, 3, 2) a_h = self.conv_h(x_h).sigmoid() a_w = self.conv_w(x_w).sigmoid() out = identity * a_w * a_h return out 文章Readme指出\nSiLU activation (h_swish in the code) works better than ReLU6 Either horizontal or vertical direction attention performs the same to the SE attention When applied to MobileNeXt, adding the attention block after the first depthwise 3x3 convolution works better Note sure whether the results would be better if a softmax is applied between the horizontal and vertical features ","date":"16 October 2024","externalUrl":null,"permalink":"/paperreading/cvpr/coordatt/","section":"Paper Reading","summary":"","title":"Coordinate Attention for Efficient Mobile Network Design","type":"paperreading"},{"content":"","date":"16 October 2024","externalUrl":null,"permalink":"/years/2020/","section":"Years","summary":"","title":"2020","type":"years"},{"content":"","date":"16 October 2024","externalUrl":null,"permalink":"/conferences/ijcai/","section":"Conferences","summary":"","title":"IJCAI","type":"conferences"},{"content":"","date":"16 October 2024","externalUrl":null,"permalink":"/paperreading/ijcai/","section":"Paper Reading","summary":"","title":"IJCAI","type":"paperreading"},{"content":" 链接\n作者指出了在传统卷积中通道存在的冗余问题（但是不能直接丢弃，直接丢弃会造成性能大幅度下降），提出了一种新的卷积操作，称之为SPConv，只在部分通道上执行昂贵的3x3卷积，而在剩余通道执行1x1卷积，并使用超参数$\\alpha$进行比例控制。\n如图所示，是一个即插即用的模块，可以用于替换其它网络结构中的3X3卷积。\n具体如下，\n将特征$C_i$按比例$\\alpha$分为两部分，上部分称为Representative，下半部分称为Redundant；\n对Representative分别进行组卷积和点卷积提取特征然后进行add，组卷积降低计算量，点卷积提高通道信息交互；Redundant直接进行1x1的点卷积；\n接着使用类似于门控机制的特征融合模块对特征进行融合从而得到输出，但此处特点是没有使用卷积进一步提取特征，而是直接全局池化接Softmax\n代码如下：\nclass SPConv_3x3(nn.Module): def __init__(self, inplanes, outplanes, stride=1, ratio=0.5): super(SPConv_3x3, self).__init__() self.inplanes_3x3 = int(inplanes*ratio) self.inplanes_1x1 = inplanes - self.inplanes_3x3 self.outplanes_3x3 = int(outplanes*ratio) self.outplanes_1x1 = outplanes - self.outplanes_3x3 self.outplanes = outplanes self.stride = stride self.gwc = nn.Conv2d(self.inplanes_3x3, self.outplanes, kernel_size=3, stride=self.stride, padding=1, groups=2, bias=False) self.pwc = nn.Conv2d(self.inplanes_3x3, self.outplanes, kernel_size=1, bias=False) self.conv1x1 = nn.Conv2d(self.inplanes_1x1, self.outplanes,kernel_size=1) self.avgpool_s2_1 = nn.AvgPool2d(kernel_size=2,stride=2) self.avgpool_s2_3 = nn.AvgPool2d(kernel_size=2, stride=2) self.avgpool_add_1 = nn.AdaptiveAvgPool2d(1) self.avgpool_add_3 = nn.AdaptiveAvgPool2d(1) self.bn1 = nn.BatchNorm2d(self.outplanes) self.bn2 = nn.BatchNorm2d(self.outplanes) self.ratio = ratio self.groups = int(1/self.ratio) def forward(self, x): b, c, _, _ = x.size() x_3x3 = x[:,:int(c*self.ratio),:,:] x_1x1 = x[:,int(c*self.ratio):,:,:] out_3x3_gwc = self.gwc(x_3x3) if self.stride ==2: x_3x3 = self.avgpool_s2_3(x_3x3) out_3x3_pwc = self.pwc(x_3x3) out_3x3 = out_3x3_gwc + out_3x3_pwc out_3x3 = self.bn1(out_3x3) out_3x3_ratio = self.avgpool_add_3(out_3x3).squeeze(dim=3).squeeze(dim=2) # use avgpool first to reduce information lost if self.stride == 2: x_1x1 = self.avgpool_s2_1(x_1x1) out_1x1 = self.conv1x1(x_1x1) out_1x1 = self.bn2(out_1x1) out_1x1_ratio = self.avgpool_add_1(out_1x1).squeeze(dim=3).squeeze(dim=2) out_31_ratio = torch.stack((out_3x3_ratio, out_1x1_ratio), 2) out_31_ratio = nn.Softmax(dim=2)(out_31_ratio) out = out_1x1 * (out_31_ratio[:,:,1].view(b, self.outplanes, 1, 1).expand_as(out_1x1))\\ + out_3x3 * (out_31_ratio[:,:,0].view(b, self.outplanes, 1, 1).expand_as(out_3x3)) return out 代码中作者直接简单的对卷积进行了区域划分，其实是有点不合理的。\n卷积的计算复杂度由$\\alpha$和$g$来进行控制，其中g为组卷积的数量，文章固定为2组，$\\alpha$在实验中的最优为$\\frac{1}{2}$.\n对比实验没什么看的必要，作者的baseline选的较低，下面看看消融。\n重要的是，特征冗余不能直接drop掉，里面还是有信息的，其它的模块消融看看就好。\n","date":"16 October 2024","externalUrl":null,"permalink":"/paperreading/ijcai/spconv/","section":"Paper Reading","summary":"","title":"Split to Be Slim: An Overlooked Redundancy in Vanilla Convolution","type":"paperreading"},{"content":"","date":"15 October 2024","externalUrl":null,"permalink":"/conferences/arxiv/","section":"Conferences","summary":"","title":"Arxiv","type":"conferences"},{"content":"","date":"15 October 2024","externalUrl":null,"permalink":"/paperreading/arxiv/","section":"Paper Reading","summary":"","title":"Arxiv","type":"paperreading"},{"content":"探究的是紧凑模型的训练策略,包括数据增强,知识蒸馏,重参数化,lr schedule等.\n但不想记,太麻烦了,截几个可能用得到的图得了\n","date":"15 October 2024","externalUrl":null,"permalink":"/paperreading/arxiv/ghostnetv3/","section":"Paper Reading","summary":"","title":"GhostNetV3: Exploring the Training Strategies  for Compact Models","type":"paperreading"},{"content":"","date":"15 October 2024","externalUrl":null,"permalink":"/years/2022/","section":"Years","summary":"","title":"2022","type":"years"},{"content":"出现在ViT之后，是对GhostNet的改进，GhostNet是纯粹的CNN，缺乏长距离特征提取能力，作者也想要利用自注意力中的全局特征提取能力，但又不想使用$n^2$复杂度的softmax自注意力，于是提出了GhostNetV2.\n如下图所示，使用FC layer对特征图依次进行特征提取，也可以使网络中的每个特征点关注到全局特征。\n具体代码操作实现中则是使用两个卷积进行实现，分别是1×5和5×1的卷积。\n网络核心代码如下：\nclass GhostModuleV2(nn.Module): def __init__(self, inp, oup, kernel_size=1, ratio=2, dw_size=3, stride=1, relu=True,mode=None,args=None): super(GhostModuleV2, self).__init__() self.mode=mode self.gate_fn=nn.Sigmoid() if self.mode in [\u0026#39;original\u0026#39;]: self.oup = oup init_channels = math.ceil(oup / ratio) new_channels = init_channels*(ratio-1) self.primary_conv = nn.Sequential( nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//2, bias=False), nn.BatchNorm2d(init_channels), nn.ReLU(inplace=True) if relu else nn.Sequential(), ) self.cheap_operation = nn.Sequential( nn.Conv2d(init_channels, new_channels, dw_size, 1, dw_size//2, groups=init_channels, bias=False), nn.BatchNorm2d(new_channels), nn.ReLU(inplace=True) if relu else nn.Sequential(), ) elif self.mode in [\u0026#39;attn\u0026#39;]: self.oup = oup init_channels = math.ceil(oup / ratio) new_channels = init_channels*(ratio-1) self.primary_conv = nn.Sequential( nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//2, bias=False), nn.BatchNorm2d(init_channels), nn.ReLU(inplace=True) if relu else nn.Sequential(), ) self.cheap_operation = nn.Sequential( nn.Conv2d(init_channels, new_channels, dw_size, 1, dw_size//2, groups=init_channels, bias=False), nn.BatchNorm2d(new_channels), nn.ReLU(inplace=True) if relu else nn.Sequential(), ) self.short_conv = nn.Sequential( nn.Conv2d(inp, oup, kernel_size, stride, kernel_size//2, bias=False), nn.BatchNorm2d(oup), nn.Conv2d(oup, oup, kernel_size=(1,5), stride=1, padding=(0,2), groups=oup,bias=False), nn.BatchNorm2d(oup), nn.Conv2d(oup, oup, kernel_size=(5,1), stride=1, padding=(2,0), groups=oup,bias=False), nn.BatchNorm2d(oup), ) def forward(self, x): if self.mode in [\u0026#39;original\u0026#39;]: x1 = self.primary_conv(x) x2 = self.cheap_operation(x1) out = torch.cat([x1,x2], dim=1) return out[:,:self.oup,:,:] elif self.mode in [\u0026#39;attn\u0026#39;]: res=self.short_conv(F.avg_pool2d(x,kernel_size=2,stride=2)) x1 = self.primary_conv(x) x2 = self.cheap_operation(x1) out = torch.cat([x1,x2], dim=1) return out[:,:self.oup,:,:]*F.interpolate(self.gate_fn(res),size=(out.shape[-2],out.shape[-1]),mode=\u0026#39;nearest\u0026#39;) ","date":"15 October 2024","externalUrl":null,"permalink":"/paperreading/nips/ghostnetv2/","section":"Paper Reading","summary":"","title":"GhostNetV2: Enhance Cheap Operation with Long-Range Attention","type":"paperreading"},{"content":"","date":"15 October 2024","externalUrl":null,"permalink":"/conferences/nips/","section":"Conferences","summary":"","title":"NIPS","type":"conferences"},{"content":"","date":"15 October 2024","externalUrl":null,"permalink":"/paperreading/nips/","section":"Paper Reading","summary":"","title":"NIPS","type":"paperreading"},{"content":"模型在提取特征的过程中会产生大量冗余的特征，一方面这会导致大量的计算，另一方面这些冗余中也包含了特征之间的相关性并没有被很好的利用。\n有些特征直接非常相似，被作者称为相互的“Ghost”，作者认为这些特征不需要通过卷积来生成，而可以使用更加廉价的操作来进行转变得到。\n方法其实很简单，就是三步操作，先看代码\nclass GhostModule(nn.Module): def __init__(self, inp, oup, kernel_size=1, ratio=2, dw_size=3, stride=1, relu=True): super(GhostModule, self).__init__() self.oup = oup init_channels = math.ceil(oup / ratio) new_channels = init_channels*(ratio-1) self.primary_conv = nn.Sequential( nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//2, bias=False), nn.BatchNorm2d(init_channels), nn.ReLU(inplace=True) if relu else nn.Sequential(), ) self.cheap_operation = nn.Sequential( nn.Conv2d(init_channels, new_channels, dw_size, 1, dw_size//2, groups=init_channels, bias=False), nn.BatchNorm2d(new_channels), nn.ReLU(inplace=True) if relu else nn.Sequential(), ) def forward(self, x): x1 = self.primary_conv(x) x2 = self.cheap_operation(x1) out = torch.cat([x1,x2], dim=1) return out[:,:self.oup,:,:] 特征x进行普通的卷积得到x1 接着对x1进行线性变换（代码使用深度卷积实现） 将x1和x2进行拼接即可得到输出 将Ghost进行堆叠即可得到其bottleneck\n结果自然是又好又快，在目标检测也是如此。\n值得注意的是，网络使用了和MobileNet一样的宽乘系数(Width Multiplier)，可以用于控制网络输入和输出通道的大小。\n","date":"15 October 2024","externalUrl":null,"permalink":"/paperreading/cvpr/ghostnet/","section":"Paper Reading","summary":"","title":"GhostNet: More Features from Cheap Operations","type":"paperreading"},{"content":"","date":"23 July 2024","externalUrl":null,"permalink":"/conferences/iclr/","section":"Conferences","summary":"","title":"ICLR","type":"conferences"},{"content":"","date":"23 July 2024","externalUrl":null,"permalink":"/paperreading/iclr/","section":"Paper Reading","summary":"","title":"ICLR","type":"paperreading"},{"content":"","date":"23 July 2024","externalUrl":null,"permalink":"/paperreading/iclr/zipformer/","section":"Paper Reading","summary":"","title":"ZIPFORMER: A FASTER AND BETTER ENCODER FOR AUTOMATIC SPEECH RECOGNITION","type":"paperreading"},{"content":"2022的ICLR，想要降低ViT的网络复杂度的文章。\n动机如图所示，将一些背景mask掉，ViT可以正确分类；mask掉主体，ViT则不可以正确识别。因此一些杂乱的背景对网络准确识别的贡献较小，可以在网络训练中进行删除或者融合。\n作者实验发现，直接删除会较大影响网络性能，因此选择了一种融合的策略来应对这些不重要的token。\n下图为本文的方法，ViT在自己自注意力计算的时候会得到一个token与其它token的softmax分数，该分数可以视为token的重要性权重。\n在进行分类的时候，只使用cls token，因此其系数（softmax分数）可以视作其它token的权重，系数越大则该token越重要。\n因此，就可以想到使用topk算法来筛选出最重要的token进行保留，其不重要的token则可以使用下面的公式进行加权融合。\n","date":"23 July 2024","externalUrl":null,"permalink":"/paperreading/iclr/evit/","section":"Paper Reading","summary":"","title":"NOT ALL PATCHES ARE WHAT YOU NEED: EXPEDITING VISION TRANSFORMERS VIA TOKEN REORGANIZATIONS","type":"paperreading"},{"content":"2022的NIPS，关于Token Sparsification的一篇文章，目的是为了模型加速，其思想和方法都比较简单。\n就是训练一个判别器去进行token的选择，留下重要的，直接删掉不重要的。\n但这有两个问题：\n1.直接删掉会使得网络漏掉一些信息\n2.这个判别器P怎么样才能在网络中训练，也就是说怎么样可以使得它也反向传播，更新参数，实现端到端的训练。\n","date":"23 July 2024","externalUrl":null,"permalink":"/paperreading/nips/dynamicvit/","section":"Paper Reading","summary":"","title":"DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification","type":"paperreading"},{"content":"2021NIPS的一篇文章，在ViT推出不久就跟进了。\n作者认为，在传统的ViT中只使用class token和hard label进行监督，这样子浪费了image tokens中含有的丰富信息，如果加以利用，则可以提升性能。\n文章的方法类似于蒸馏，使用一个更大更好的教师模型去监督学生模型，从而提升模型性能。\n使用一个事先预训练好的模型，进行离线操作得到输入图像对应的密集分数图（Dense score map），与input image相同，将该map打成patch块（得到token labeling），两者一一对应，从而就可以使用token label来进行image token的监督。\n损失函数如下：\n与传统的ViT相比，多了关于image token的监督信号（损失）\n此外，作者还对数据增强中的CutMix做了改进，命名为MixToken\n目的就是为了防止标签混淆，传统的CutMix会造成一个token中有不同的图像，这样子标签就不知道怎么给，采用掩码M后对token进行mix操作就可以解决这个问题。\n","date":"23 July 2024","externalUrl":null,"permalink":"/paperreading/nips/lv-vit/","section":"Paper Reading","summary":"","title":"All Tokens Matter: Token Labeling for Training Better Vision Transformers","type":"paperreading"},{"content":"","date":"16 July 2024","externalUrl":null,"permalink":"/notes/","section":"Notes","summary":"","title":"Notes","type":"notes"},{"content":"癫痫是常见的神经系统疾病之一。血氧水平依赖的功能磁共振成像（blood oxygen level dependent functional magnetic resonance imaging，BOLD‑fMRI）技术作为一种高空间分辨率、重复易行的无创技术，已在癫痫临床和研究方面有广泛应用。\n功能磁共振 （functional magnetic resonance imaging，fMRI）也可以对癫痫 发放活动引起的血氧水平依赖（blood oxygen level dependent，BOLD）活动进行观察。\n同步脑电图‑功能磁共振成像（simultaneous electroencephalogram and functional MRI， EEG‑fMRI）利用同步采集的脑电图（electroencephalogram， EEG）数据辨认癫痫电发放活动，在fMRI上获得癫痫发放活 动空间定位信息。其结合了EEG的高时间分辨率和fMRI 的真实空间、高空间分辨率的优点，以多模态联合的方式 对癫痫患者脑功能改变情况进行全面观察。\n癫痫 # 癫痫是一种慢性脑部疾病，其主要特点是反复发作。这些发作由一组脑细胞的异常放电引起。 发病原因： 神经元异常放电：癫痫的根本原因是大脑神经元的异常放电。这些异常放电可能由多种因素引起，如肌肉收缩、大脑皮质发育障碍、脑部肿瘤、头外伤、中枢神经系统感染等。遗传因素也可能与癫痫有关。 年龄不限：癫痫并不局限于特定年龄段，但在孩童和老年人中较为常见。 症状： 突然发作：癫痫的主要表现是突然、毫无缘由的发作。每次发作的症状可能不同，但同一个患者每次发作的表现通常相似。 多样性症状：症状可能包括意识瞬间丧失和跌倒、肢体感觉异常、出现幻觉、重复的单词或音节、身体或眼睛的旋转等。 相关技术 # 脑电图（electroencephalogram, EEG) # EEG 是一种记录大脑电活动的无创性检查方法。\n原理：通过在头皮上放置电极，测量大脑神经元的电活动。这些电信号被放大并记录下来，形成脑电图。 时间分辨率：EEG具有非常高的时间分辨率，可以捕捉到毫秒级的电活动变化。 波段划分： δ波（0.5~3Hz）：在婴儿期、极度疲劳或昏睡状态下记录到。 θ波（4~7Hz）：在成年人意志受挫、抑郁或精神病患者中显著。 α波（8~13Hz）：清醒、安静闭眼时最明显，光刺激或其他刺激时消失。 β波（14~30Hz）：精神紧张、情绪激动或亢奋时出现。 应用：用于研究事件相关电位（ERP）、脑波频谱、癫痫活动等。 磁共振成像（MRI） # MRI 是一种基于核磁共振原理的医学成像技术，用于影像诊断。它利用人体组织中某种原子核的核磁共振现象，通过处理射频信号，重建出人体某一层面的图像。MRI可以提供大脑的结构图，显示某一时刻的情况。这对于比较不同人的特定脑区大小或检测特定脑部异常（例如肿瘤）非常有用。\n原理：利用人体组织中某种原子核的核磁共振现象，通过处理射频信号，重建出人体某一层面的图像。 MRI提供的信息量大且安全，对疾病的诊断具有潜在优越性，不涉及电离辐射 。\n功能磁共振成像（fMRI） # 原理：使用磁场和无害的无线电波来获取大脑的结构和功能信息。fMRI测量血氧水平变化，间接反映神经活动。 空间分辨率：fMRI提供高空间分辨率，可以显示不同脑区的活动。 应用：用于研究大脑功能、任务执行、情感、记忆等。 ","date":"16 July 2024","externalUrl":null,"permalink":"/notes/%E7%99%AB%E7%97%AB%E8%B0%83%E7%A0%94/","section":"Notes","summary":"","title":"癫痫调研","type":"notes"},{"content":"","date":"7 July 2024","externalUrl":null,"permalink":"/conferences/aaai/","section":"Conferences","summary":"","title":"AAAI","type":"conferences"},{"content":"","date":"7 July 2024","externalUrl":null,"permalink":"/paperreading/aaai/","section":"Paper Reading","summary":"","title":"AAAI","type":"paperreading"},{"content":"AAAI2024的一篇文章，和CF-VIT和LF-VIT是相似的，都是通过两步的计算：由粗到细对ViT进行优化，也是通过EMA计算得到的注意力图进行细化计算。\n整体框图如下\n是在人体姿态检测的一篇工作，前面的编码部分和CF-VIT如出一辙，先通过小分辨率的图得到注意力图和粗计算的结果， 再通过注意力图作用到大分辨率的图像从而进一步的提取特征的同时减少计算量。\n与CF-VIT的不同则是：\n1.在输入多了一些token，作者成为key token，也就是关键点token\n2.对得到的特征通过了解码器得到最终结果\n","date":"7 July 2024","externalUrl":null,"permalink":"/paperreading/aaai/sharpose/","section":"Paper Reading","summary":"","title":"SHaRPose: Sparse High-Resolution Representation for Human Pose Estimation","type":"paperreading"},{"content":"AAAI2024的一篇文章，总体思想和CF-VIT相似，实际上就是对CF-VIT的一点改进，也可以说只是改变。\n模型框图、行文方式等基本相似\n主要的不同体现在对细粒度中token的选择，对于CF-VIT是在全局中进行topk操作得到最相似的n个token，LF-VIF则是先使用一个mxm滑动窗口去计算每个窗口中的注意力得分总和，再根据总的得分选择得分最高的窗口作为下一步细粒度操作的对象。\n具体来说就是，先得到一个得分最高的窗口，然后在得分最高的窗口里面再进行一次注意力分数排序，再去掉一些杂乱的背景，从而就可以使用更少的token进行进一步操作，进一步优化了计算复杂度。\n对于那些在细粒度选择中被抛弃的token，作者也没有直接舍弃它们，而是通过一个残差操作将其添加到网络输入中，从而提供更加详细的背景信息。\n文章对其和CF-VIT进行了可视化处理，可以看到CF-VIT是从全图去进行稀疏化操作的，而LF-VIT则是先选择一个窗口，再在窗口中再一次进行选择，这就导致其在自然图像分类中可以更好的找到目标，因为自然图像的分类往往取决于图像中的一小块主要区域。\n而在医学影像中，个人觉得还是CF-VIT更加具有优势和可解释性。\n对于RP分级，其色素往往分布在眼底彩照很多地方，并且视盘、血管等也会影响其分级，因此我觉得对全图取top-k操作的CF-ViT相对于只在一小块区域中做细粒度操作的LF-ViT更具合理性。\n","date":"7 July 2024","externalUrl":null,"permalink":"/paperreading/aaai/lf-vit/","section":"Paper Reading","summary":"","title":"LF-ViT: Reducing Spatial Redundancy in Vision Transformer for Efficient Image Recognition","type":"paperreading"},{"content":" AAAI2023的一篇文章，为了解决ViT在处理图片时存在计算成本高和空间维度冗余的问题，也是一篇关于ViT稀疏化的文章。具体来说，ViT在处理图像时，需要将2D图像打成许多小的patch块，这里面包含了对模型没有用的冗余信息，并且这些冗余会大大增加计算负担。\n总览 # 作者做了实验证明了两点：\n图1(a)：将每个图片分割为14x14的patch块，利用注意力图来选择100个最高评分和100个最低评分的patch块，分别送入到分类头可以发现高得分的patch块优于低得分，这说明可以通过筛选高得分块来进行计算从而进行稀疏化\n图1(b)：对最后一个编码器进行了可视化处理，可以发现7x7和14x14的patch块可以得到相似的注意力区域，图像可以通过ViT模型在短长度的token序列中得到很好的识别\n接着作者分别使用14x14和7x7的patch块进行了分类实验：\n使用更长的序列进行训练需要使用4.2的计算代价才能得到6%的性能提升。\n因此，可以使用一种新的训练策略，一种由粗到细的ViT（coarse-to-fine vision transformer，CFViT），如图2所示，在粗粒度推理阶段，将输入图像分割成短长度的patch序列进行经济的分类；如果图像未被准确识别，则在细粒度推理阶段，识别出信息丰富的patch并进一步进行细粒度分割。\n模型框架 # 总体框图 # CF-ViT的核心思想是通过两个阶段的推理过程来减少计算量，同时保持性能。\n模型主要有：\n粗粒度推理阶段（Coarse Inference Stage）:\n在这个阶段，CF-ViT将输入图像分割成较小数量的粗粒度patches，形成较短的token序列。 使用这个较短的token序列进行分类，可以减少计算量，因为涉及到的patches（tokens）数量较少。 如果这个阶段的分类结果具有高置信度，推理过程将终止 信息区域识别（Informative Region Identification）:\n如果粗粒度推理阶段的分类结果置信度不高，CF-ViT会识别出图像中的信息丰富区域。 通过使用全局类注意力（global class attention）来评估每个patch的重要性，选择那些对分类结果影响最大的patches。 细粒度推理阶段（Fine Inference Stage）:\n对于识别出的信息丰富区域，CF-ViT将这些粗粒度patches进一步分割成更细粒度的patches。 这种细粒度分割有助于更准确地表示和识别图像中的复杂区域或对象。 特征重用（Feature Reuse）:\n为了避免在细粒度分割过程中丢失局部信息，CF-ViT引入了特征重用机制。 通过将粗粒度patches的特征信息注入到细粒度patches中，增强了模型对局部细节的表示能力。 训练策略（Training Strategy）:\n在训练过程中，CF-ViT总是执行细粒度推理阶段，以确保模型能够学习到在粗粒度和细粒度推理阶段都能准确分类的能力。 使用交叉熵损失和Kullback-Leibler散度来训练模型，使得粗粒度和细粒度推理阶段的输出都能逼近真实标签。 具体内容 # 粗粒度推理阶段（Coarse Inference Stage） # 这一步的输入是112x112大小的图像，当patch size为16时可以得到7x7=49个patch块，加上cls_token共有50个，通过ViT后则进行判断，如果得到了高置信度的结果则直接输出，否则执行后续步骤。\n具体如下图所示，将ViT的输出通过分类头后则可以得到每类的置信度，如果p大于阈值则输出。\n信息区域识别（Informative Region Identification） # 细粒度推理阶段（Fine Inference Stage） # 模型在112x112的图像上得不到高置信度的结果则会进行细粒度的推断，此时输入图像大小为224x224，通过粗阶段得到的注意力图（attn_map）使用topk算法去选择哪些token是重要的，将这些区域筛选出来去进行更进一步的计算，从而得到更细致的特征，而不重要的特征则保持不变，从而减少计算。\n图4的右中和右下角在代码中的体现是信息区域识别部分。\n具体来说：\n1.使用EMA算法得到更全面的注意力图，注意力图反应了cls_token和其它图像信息token的相关性，越高则说明图片该区域对模型判断越重要，也就是更加需要注意的地方。\n2.公式9和公式10是指特征选择，对于重要特征则将其高分辨率图的一个区域划分为四个区域得到更细腻的特征用于分类，使用该特征和原始不重要的特征进行相加则可以得到第二个ViT的输入。 特征重用（Feature Reuse） # 图4的右上角也就是下图截取出来的部分为文中使用的特征重用，是对粗粒度信息的再次利用，在代码中的体现其实就是对ViT得到的特征进行MLP和细粒度特征进行维度对齐方便进行信息区域识别。\n模型大致训练过程如下\n1. 初始化模型参数和优化器 - 设置图像大小、patch大小、通道数、类别数、嵌入维度等 - 初始化优化器，例如 Adam 或 SGD 2. 开始训练循环 for 每一个 epoch 执行： for 每一个 batch (粗粒度图像，细粒度图像，标签) 执行： a. 粗粒度推理 - 前向传播通过粗粒度图像 - 计算输出和全局注意力图 b. 全局注意力更新 - 使用 EMA 更新公式：global_attention = β * prev_attention + (1-β) * current_attention c. 细粒度推理 - 根据全局注意力选择重要区域 - 前向传播通过细粒度图像和重用特征 d. 计算损失 - 使用交叉熵或其他适合的损失函数 e. 反向传播和参数更新 - 调用 optimizer.step() 更新模型权重 ","date":"7 July 2024","externalUrl":null,"permalink":"/paperreading/aaai/cf-vit/","section":"Paper Reading","summary":"","title":"CF-ViT: A General Coarse-to-Fine Method for Vision Transformer","type":"paperreading"},{"content":"","date":"17 June 2024","externalUrl":null,"permalink":"/tags/ddp/","section":"Tags","summary":"","title":"DDP","type":"tags"},{"content":" DDP # DistributedDataParallel支持单卡多机和多卡多机，速度相对于较早的DataParallel更快。\ntorch.distributed.launch # torch.distributed.launch是多GPU启动的一种方法，torch.multiprocessing也可以用于多GPU启动。\n1.初始化各进程环境 # def init_distributed_mode(args): if \u0026#39;RANK\u0026#39; in os.environ and \u0026#39;WORLD_SIZE\u0026#39; in os.environ: args.rank = int(os.environ[\u0026#34;RANK\u0026#34;]) args.world_size = int(os.environ[\u0026#39;WORLD_SIZE\u0026#39;]) args.gpu = int(os.environ[\u0026#39;LOCAL_RANK\u0026#39;]) elif \u0026#39;SLURM_PROCID\u0026#39; in os.environ: args.rank = int(os.environ[\u0026#39;SLURM_PROCID\u0026#39;]) args.gpu = args.rank % torch.cuda.device_count() else: print(\u0026#39;Not using distributed mode\u0026#39;) args.distributed = False return args.distributed = True torch.cuda.set_device(args.gpu) args.dist_backend = \u0026#39;nccl\u0026#39; print(\u0026#39;| distributed init (rank {}): {}\u0026#39;.format( args.rank, args.dist_url), flush=True) dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size, rank=args.rank) dist.barrier() 2.将数据分配到不同GPU # train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset) val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset) train_batch_sampler = torch.utils.data.BatchSampler( train_sampler, batch_size, drop_last=True) 3. 将分配好的数据组成一个个batch # train_batch_sampler = torch.utils.data.BatchSampler( train_sampler, batch_size, drop_last=True) 4.数据传入到dataloader # train_loader = DataLoader(train_dataset, batch_sampler=train_batch_sampler, pin_memory=True, num_workers=nw, collate_fn=train_dataset.collate_fn) val_loader = DataLoader(val_dataset, batch_size=batch_size, sampler=val_sampler, pin_memory=True, num_workers=nw, collate_fn=val_dataset.collate_fn) 对于val，不需要第三步，因为val只需要把所有数据都进行测试，与顺序、批次等无关。\n5.转换DDP模型 # model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu]) 6.在多个GPU求平均 # def reduce_value(value, average=True): world_size = get_world_size() if world_size \u0026lt; 2: # 单GPU的情况 return value with torch.no_grad(): dist.all_reduce(value) if average: value /= world_size return value def train(train_loader, model, criterion, optimizer,device): mean_loss = torch.zeros(1).to(device) sum_num = torch.zeros(1).to(device) model.train() if is_main_process(): train_loader = tqdm(train_loader, file=sys.stdout) for step , (images, target) in enumerate(train_loader): images = images.to(device, non_blocking=True) target = target.to(device, non_blocking=True) output = model(images) loss = criterion(output, target) loss.backward() loss = reduce_value(loss, average=True) mean_loss = (mean_loss * step + loss.detach()) / (step + 1) # update mean losses pred = torch.max(output, dim=1)[1] sum_num += torch.eq(pred, target.to(device)).sum() optimizer.step() optimizer.zero_grad() sum_num = reduce_value(sum_num, average=False) if device != torch.device(\u0026#34;cpu\u0026#34;): torch.cuda.synchronize(device) return mean_loss.item(),sum_num.item() 7.启动 # python -m torch.distributed.launch --nproc_per_node=8 --use_env train_multi_gpu_using_launch.py 其中nproc_per_node为并行GPU的数量 如果要指定使用某几块GPU可使用如下指令，例如使用第1块和第2块GPU进行训练： CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node=2 --use_env train_multi_gpu_using_launch.py 注意事项 # 1.rank # 由于使用了多个GPU也就造成了多个进程，如果不限定一些rank的操作则会由于在不同进程中的反复操作造成一些问题\n例如在打印或者保存结果的时候可以指定rank==0\nif rank == 0: ######### 2.SyncBatchNorm # 同步批量归一化（Synchronized Batch Normalization），是一种适用于分布式训练的批量归一化技术。在标准的批量归一化（Batch Normalization）中，每个 GPU（或进程）只会使用自己的批次数据来计算归一化参数（均值和方差），这可能会在小批量数据时造成统计上的不稳定。当使用分布式训练时，由于每个 GPU 只看到部分数据，这个问题尤为明显。\n因此需要将模型中的普通BN层转为具有同步功能的BN层，代码实现很简单，使用下面这行代码Pytorch就会自动将模型中的所有BN层转为SyncBatchNorm\nmodel = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device) 需要注意的是，使用了SyncBatchNorm会造成训练时间的增加\n","date":"17 June 2024","externalUrl":null,"permalink":"/python/tricks/ddp/ddp/","section":"Python","summary":"","title":"单卡多机训练","type":"python"},{"content":" AAAI2024关于注意力稀疏化的一篇文章，利用DPCKNN（density peaks clustering,密度峰值聚类）来进行特征选择和聚合从而降低计算量并解决Transformer方法注意力崩溃（attention collapse）的问题。\n首先需要先了解一下什么是DPC和DPCKNN，DPC是2014年Science上的一篇文章，DPCKNN16年发表在KNOWLEDGE-BASED SYSTEMS上，是对DPC的改进。\nDPC # 概述 # DPC是一种不需要迭代的，可以一次性找到聚类中心的方法聚类方法\n基于两个思想：\n（1）聚类中心的密度（Density）应当比较大\n（2）聚类中心应当离比其密度更大的点较远\n点1密度最大，是一个聚类中心；点2,6,4密度也比较大，但是距离比他们密度更大的点（点1）太近，所以不是聚类中心；\n点10 密度较大，且离密度比它大的点（1,2,4,6）较远，所以是聚类中心。\n在该算法中，主要需要为每个点计算两个参数：\n（1）局部密度$\\rho_i$\n硬截断方法 (Hard Cutoff):\n$$ \\rho_i = \\sum_{j} \\chi(d(x_i, x_j) - d_c) $$\n软截断方法 (Soft Cutoff):\n$$ \\rho_i = \\sum_{j} e^{-\\left(\\frac{d(x_i, x_j)}{d_c}\\right)^2} $$\n（2）到密度比其大的点的最小距离 $$ \\delta_i = \\begin{cases} \\min_{j : \\rho_j \u0026gt; \\rho_i} d(x_i, x_j), \u0026amp; \\text{if } \\exists j \\text{ s.t. } \\rho_j \u0026gt; \\rho_i \\\\max_j d(x_i, x_j), \u0026amp; \\text{otherwise} \\end{cases} $$ 两者都大的点就是聚类中心点\n局部密度求解方法 # 只有是$d_c$变量\n$d_c$的求解：落在$d_c$圆区域内平均点数，占总点数的1%-2%，这里也是它的缺陷，使用DPCKNN来改善了这点，后续会说\n对于$\\rho_i$的计算有两种方法\n1.对于硬阶段方法，对每个点，以$d_c$为半径画一个圆形区域，统计其中点的数目\n$$ \\rho_i = \\sum_{j} \\chi(d(x_i, x_j) - d_c) $$\n其中，$\\chi$ 是一个指示函数，当 $d(x_i, x_j) \u0026lt; d_c$ 时为1，否则为0。这种方式计算的是在 $d_c$ 内邻居的数量。\n2.利用类高斯公式，也就是软统计\n$$ \\rho_i = \\sum_{j} e^{-\\left(\\frac{d(x_i, x_j)}{d_c}\\right)^2} $$\n这里，$e^{-\\left(\\frac{d(x_i, x_j)}{d_c}\\right)^2}$ 是一个高斯函数，用于计算每个点 $x_j$ 对点 $x_i$ 的密度贡献，距离越远贡献越小。\n在DPC（Density Peaks Clustering，密度峰值聚类）算法中，$\\delta_i$ 是一个非常关键的度量，它表示每个数据点 $x_i$ 到任何具有更高局部密度的其他点的最小距离。这个度量有助于识别潜在的聚类中心和聚类边界，因此在聚类过程中扮演着重要角色。\n$\\delta_i$ 的定义和计算 # 具体来说，$\\delta_i$ 的计算方式如下：\n首先，对于每个点 $x_i$，找到所有局部密度 $\\rho_j$ 大于 $\\rho_i$ 的点 $x_j$。 然后，计算 $x_i$ 到这些点 $x_j$ 的距离。 $\\delta_i$ 被定义为这些距离中的最小值，即： $$ \\delta_i = \\min_{j: \\rho_j \u0026gt; \\rho_i} d(x_i, x_j) $$ 其中 $d(x_i, x_j)$ 是点 $x_i$ 和 $x_j$ 之间的距离。 如果没有任何其他点的局部密度大于 $x_i$（即 $x_i$ 是局部密度最高的点），$\\delta_i$ 的值则被设置为从 $x_i$ 到数据集中所有其他点距离的最大值，表示其相对于数据集中其他所有点的“隔离程度”： $$ \\delta_i = \\max_{j} d(x_i, x_j) $$\n理论上，一个好的聚类中心应具有较高的局部密度 $\\rho$ 和较大的 $\\delta$ 值。这表示一个聚类中心不仅周围有许多其他点（高密度），而且与其他高密度点的距离较远（大的 $\\delta$），说明它位于一个密度较高区域的中心。\n在计算$\\delta_i$ 的时候会同时会记录索引j用于后续的聚类\nDPCKNN # DPCKNN（Density Peaks Clustering based on K-Nearest Neighbors，基于K最近邻的密度峰值聚类）是DPC（Density Peaks Clustering，密度峰值聚类）的一个变种，它通过引入K最近邻算法来改进局部密度的计算方式。这种改进使得算法更好地适应数据集中的局部结构，尤其是在处理具有复杂局部结构或不均匀密度分布的数据集时。\nDPCKNN与DPC的主要区别 # DPCKNN与传统的DPC算法的主要区别在于局部密度 $\\rho_i$ 的计算方法：\nDPC的局部密度计算：传统的DPC算法使用固定的截断距离 $d_c$，计算每个点 $x_i$ 在这个距离内的邻居数量（硬截断）或使用高斯函数来加权计算（软截断）。这种方法侧重于全局或较大范围的邻居关系，可能会忽视数据的微观结构特征。 $$ \\rho_i = \\sum_{j} \\chi(d(x_i, x_j) - d_c) \\quad \\text{或} \\quad \\rho_i = \\sum_{j} e^{-\\left(\\frac{d(x_i, x_j)}{d_c}\\right)^2} $$\nDPCKNN的局部密度计算：DPCKNN通过计算每个点 $x_i$ 的K个最近邻点的平均距离来定义局部密度。这种方法更加关注每个数据点的直接邻域，因此可以更精确地捕捉局部结构特征，特别是在数据密度不均或数据分布复杂的情况下。 $$ \\rho_i = \\frac{1}{k} \\sum_{x_j \\in \\text{KNN}(x_i)} e^{-d(x_i, x_j)^2} $$\n$k$：K最近邻的数量，一个超参数，选择k个邻居来进行 $\\rho_i$ 的计算。\n$\\text{KNN}(x_i)$：表示从数据集中找到的距离点 $x_i$ 最近的$k$个点的集合。\n$x_j$：属于点 $x_i$ 的K最近邻的任一点。\n$d(x_i, x_j)$：表示点 $x_i$ 和点 $x_j$ 之间的距离，通常使用欧氏距离来计算。\nDPCKNN通过考虑每个点的最近邻而非固定半径内的所有点，能更灵活地适应各种数据分布，尤其是在数据点间距离差异较大的情况下。\n引入K最近邻的方法可以提高聚类的准确性和鲁棒性，特别是对于具有复杂地形或多尺度聚类结构的数据集。\n花了好久搞明白DPC和DPCKNN，下面进行论文的记录。\n文章目的 # 这篇论文试图解决的问题是在医学图像分割中，基于Transformer的方法存在注意力崩溃（attention collapse）的问题，这使得Transformer在CNN-Transformer混合架构中往往退化成绕过模块，无法有效地捕获长距离依赖关系。具体来说，这个问题的原因包括：\n高模型复杂度：ViT具有O(n^2)的模型复杂度，随着输入token序列长度n的增加，在相对有限的标注医疗图像数据下，很难实现良好的收敛，使得Transformer在捕获长距离依赖方面的效果受限。\n严重的依赖冗余：相同模态的医学图像共享稳定的结构/视图，并且在大多数情况下依赖局部特征进行分割。因此，为所有patches/tokens建立成对依赖可能会产生严重的依赖冗余，这反过来使得捕获真正有用的长距离依赖变得更加困难。\n为了解决这些问题，论文提出了一种名为DTMFormer的即插即用（plug-n-play）Transformer模块，通过动态令牌合并来避免在冗余和重复的token上构建长距离依赖，从而追求更好的收敛性。DTMFormer包括一个基于注意力的令牌合并（ATM）模块，该模块根据特征和依赖相似性自适应地将token聚类为更少的语义token，以及一个轻量级的token重建模块（LTR），用于融合普通和语义token。通过这种方式，由于ATM基于更少的token计算自注意力，DTMFormer具有更低的复杂度，并且更易于收敛。\n文章方法 # ATM模块 # ATM模块旨在通过合并相似和冗余的令牌到更少、更有意义的令牌中，以减少冗余并增强语义丰富性。这一过程包括选择聚类中心和围绕这些中心聚类令牌。\n生成输入特征映射和令牌 # 输入特征映射 $X \\in \\mathbb{R}^{H \\times W \\times C}$：通过大小为 $p \\times p$ 的补丁生成一系列令牌 $I \\in \\mathbb{R}^{N \\times C\u0026rsquo;}$，其中 $C\u0026rsquo; = p^2 \\cdot C$ 是由补丁大小确定的令牌通道数，而 $N = \\frac{HW}{p^2}$ 是总令牌数。 自注意力和依赖性评分 # 自注意力机制：对令牌序列 $I$ 应用 $h$ 头自注意力，生成 $h$ 个注意力图 $M \\in \\mathbb{R}^{h \\times N \\times N}$。\n依赖性分数 $S_d$ 的计算： $$ S_d = \\text{norm}\\left(\\sum_{i=1}^{h/2} \\sum_{j=1}^N M_{i,j,k}\\right) \\tag1 $$ 计算M的总和，并对h/2个注意力头求和，最后进行归一化。\n使用DPCKNN进行聚类和稀疏化处理 # $$ D_{\\text{token}}(i, j) = \\frac{|x_i - x_j|^2}{\\sqrt{C\u0026rsquo;}} \\tag2 $$ $$ D_{\\text{attn}}(i, j) = \\frac{|y_i - y_j|^2}{\\sqrt{N}} \\tag3 $$\n$$ D = (1-\\alpha)D_{\\text{token}} + \\alpha D_{\\text{attn}} \\tag4 $$\n$$ \\rho_i = \\exp\\left(-\\sum_{j \\in \\text{kNN}(D(i))} D(i, j)\\right) \\tag5 $$ $$ \\delta_i = \\begin{cases} \\min_{j:\\rho_j \u0026gt; \\rho_i} D(i, j) \u0026amp; \\text{if } \\exists j \\text{ s.t. } \\rho_j \u0026gt; \\rho_i \\ \\max_j D(i, j) \u0026amp; \\text{otherwise} \\end{cases} \\tag6 $$\n$$ S_f^i = \\rho_i \\times \\delta_i \\tag7 $$\n$$ S = S_d + S_f \\tag8 $$\n首先根据公式2和3对token和注意力图计算所有token对的距离分数，使用超参数$\\alpha$得到最早的距离矩阵，得到距离矩阵后就根据DCPKNN来进行计算得到局部密度和索引，之后每个标记 i 的特征得分计算为公式7\n在此基础上选择得分最高的前 rN 个标记（ r 是稀疏比）作为合并的中心/语义标记。\nLTR模块 # LTR模块比较简单，和整体框图里的操作差不多，需要先将稀疏化后的特征进行上采样。\n原始特征和上采样的特征均通过线性层后进行融合。\n在下一层注意力计算的时候，融合后的特征作为Q，原始特征作为K和V。\n","date":"8 June 2024","externalUrl":null,"permalink":"/paperreading/aaai/dtmformer/","section":"Paper Reading","summary":"","title":"DTMFormer: Dynamic Token Merging for Boosting Transformer-Based Medical Image Segmentationer","type":"paperreading"},{"content":" AAAI2024的一篇文章，是一篇关于模态融合的文章，设计了一个通用的多模态融合器，称为BA（a universal bi-directional adapter），可以相互交叉提示多模态数据，其结构简单高效，参数量少。\n在目标跟踪领域中，通常是将一种模态（通常是 RGB）作为主导模态，将另一种模态作为辅助模态。这些方法忽略了多模态数据的动态主导相关性，使得难以充分利用复杂场景中的互补多模态信息，从而限制了跟踪性能，而这篇文章没有预设固定的主导模态-辅助模态，而是BAT从辅助模态到主导模态的变化中动态地提取有效信息。\nBA采用模块化设计，分别嵌入多头自注意力阶段和MLP阶段，也就是在一个Transformer Encoder中插入两个BA，进行两次模态交互，如Figure2所示。\nFigure3展示了BA的内部结构，其构造非常简单，对于一种模态，比如论文中提到的RGB，将RGB Tokens通过由降维-线性-升维操作组成的BA块从而得到RGB的feature prompts，该feature prompts作为RGB的特征输入到另外一个模态IR中，从而进行模态的交互。对于IR模态进行相同的操作，得到IR的feature prompts输入到RGB模态中。\n在整个过程中，只有BA模块是未冻结的，其余的Transformer Encoder和Prediction head均冻结。\n整篇文章看下来还是比较简单的，主要就是设计了一个轻量化，并且可以互相交互的多模态融合模块，该模块可以随意加入到都使用Transformer作为编码器的多模态模型中。\n","date":"19 May 2024","externalUrl":null,"permalink":"/paperreading/aaai/bat/","section":"Paper Reading","summary":"","title":"Bi-directional Adapter for Multi-modal Tracking","type":"paperreading"},{"content":"","date":"19 May 2024","externalUrl":null,"permalink":"/tags/multi-modal/","section":"Tags","summary":"","title":"Multi-Modal","type":"tags"},{"content":" 整体概述 # 多模态的数据融合可以为网络分类提供补充信息从而获得更加的性能，但在实践中多模态的数据往往不容易获得，尤其是基因组的数据。对于这个问题，这篇文章采用了对比知识蒸馏方法，提出了一种差异和梯度引导的蒸馏框架（discrepancy and gradient-guided distillation framework ），在训练阶段使用配对的病理学\u0026ndash;基因组数据，而在推理的时候仅使用病理学图像，从而将多模态的教师的知识转移给学生。\n总共有两个模块，一个是教师端的Discrepancy-induced Contrastive Distillation (DCDistill)模块，一个是学生端的Gradient-guided Knowledge Refinement (GK-Refine) 模块。\nDiscrepancy-induced Contrastive Distillation # 传统的对比知识蒸馏会为一个样本选择一个正样本和随机采样k个负样本，DCDistill则通过下面两个公式为样本筛选出kp个正样本和kn个负样本，这样样本更加可靠：\nds是指学生端样本间的距离，为+则是样本与正对，为-则是样本与负对，dt是教师端。\n通过这两个公式计算E的正负，（1）为正则为说明该样本为可靠的正样本，（2）为正则为可靠负样本。\n在得到正负样本后则可以通过公式（3）计算DCD损失：\n与现有随机选择对比样本的对比知识蒸馏方法相比，所提出的DC-Distill基于师生差异探索信息丰富且可靠的对比样本，允许多模态教师自适应地将最有用的知识转移到单模态学生。\nGradient-guided Knowledge Refinement # 为了提供补充知识，GK-Refine 引入了另一个单模态平均教师 Tp，它允许回顾以前的课程并提供强大的模内知识，Tp通过KL损失和DCD损失来指导学生模型，其中DCD损失与公式（3）相同。\n这样子就会有很多损失，如图1所示，共有五种损失，论文中说这代表着学生有三处知识来源：1.真实标签 2.多模态教师的知识（两个损失） 3.单模态平均教师（也是两个损失），因此需要平衡这几个损失的重要性，提出了Gradient-guided Knowledge Refinement。\n该模块允许教师根据学生的需求自适应地传递信息丰富且可靠的知识，实际上就是对损失函数做出改进，总的损失函数不是简单的将所有损失进行相加，而是对除了Lce的损失外都加了一个变量λ来进行控制，从而决定哪些损失重要，哪些损失不重要，也就是对知识进行一些筛选，学习可靠知识，降低不可靠知识带来的影响。\n具体来说就是，先对每个损失函数加一个梯度，得到：\n对于第i个知识，计算它和所有梯度损失之间的余弦相似度：\n越高的λ则证明该知识与其它知识的一致性越高，则更具有可靠性，因此应该对学生训练做出更大的贡献。相反，不可靠的知识由于与其他知识矛盾，会被赋予较小的λi。得到总损失为：\n通过调整多种知识的权重，根据其可靠性重新校准它们对学生贡献。细化后，可靠知识的梯度得到加强，不可靠知识的梯度得到减少，从而得到更好的梯度下降方向总损失，有利于学生的学习和收敛。\n","date":"18 May 2024","externalUrl":null,"permalink":"/paperreading/miccai/dcdistill/","section":"Paper Reading","summary":"","title":"Discrepancy and Gradient-Guided Multi-modal Knowledge Distillation for Pathological Glioma Grading","type":"paperreading"},{"content":"","date":"18 May 2024","externalUrl":null,"permalink":"/conferences/miccai/","section":"Conferences","summary":"","title":"MICCAI","type":"conferences"},{"content":"","date":"18 May 2024","externalUrl":null,"permalink":"/paperreading/miccai/","section":"Paper Reading","summary":"","title":"MICCAI","type":"paperreading"},{"content":"","date":"11 May 2024","externalUrl":null,"permalink":"/tags/python/","section":"Tags","summary":"","title":"Python","type":"tags"},{"content":"有时候不来工位的话就会需要对工位电脑进行远程控制，但经常发现校园网会断开，所以就想着能不能搞个程序间隔一段时间就自动连接一下校园网从而解决网路中断问题\n下面直接给出代码\nimport schedule import time from win10toast import ToastNotifier import requests import socket def get_ip(): s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) s.connect((\u0026#39;8.8.8.8\u0026#39;, 80)) ip = s.getsockname()[0] s.close() return ip def check_and_sign_in(): print(f\u0026#34;Checking and signing in at {time.strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;)}\u0026#34;) try: r = requests.get(login_IP, timeout=1) req = r.text except: req = \u0026#39;False\u0026#39; if signed_in_title in req: # 已经连接，无需操作 pass elif not_sign_in_title in req: r2 = requests.get(sign_parameter, timeout=1) req2 = r2.text if result_return in req2: ToastNotifier().show_toast(title=\u0026#34;登录成功\u0026#34;, msg=\u0026#34;校园网状态\u0026#34;, duration=5, threaded=False) else: ToastNotifier().show_toast(title=\u0026#34;登录失败\u0026#34;, msg=\u0026#34;校园网状态\u0026#34;, duration=5, threaded=False) else: ToastNotifier().show_toast(title=\u0026#34;未连接到校园网\u0026#34;, msg=\u0026#34;校园网状态\u0026#34;, duration=5, threaded=False) login_IP = \u0026#39;http://10.9.1.3\u0026#39; not_sign_in_title = \u0026#39;上网登录页\u0026#39; result_return = \u0026#39;\u0026#34;result\u0026#34;:\u0026#34;0\u0026#34;\u0026#39; sign_parameter = f\u0026#39;http://10.9.1.3:801/eportal/?c=Portal\u0026amp;a=login\u0026amp;callback=dr1003\u0026amp;login_method=1\u0026amp;user_account=%2Cb%2C校园网账号%40ctc\u0026amp;user_password=网关密码\u0026amp;wlan_user_ip={get_ip()}\u0026amp;wlan_user_ipv6=\u0026amp;wlan_user_mac=000000000000\u0026amp;wlan_ac_ip=\u0026amp;wlan_ac_name=\u0026amp;jsVersion=3.3.3\u0026amp;v=5111\u0026#39; signed_in_title = \u0026#39;注销页\u0026#39; schedule.every().day.at(\u0026#34;08:30\u0026#34;).do(check_and_sign_in) schedule.every(60).minutes.do(check_and_sign_in) print(sign_parameter) while True: schedule.run_pending() time.sleep(1) 该代码可以在每天固定时间尝试连接网络，并且也可以设置连接频率每隔一段时间就尝试连接一次。\n如果已经连接，则直接pass，如果未连接则会进行登录操作。\n我是中国电信的网络，如果使用者也是电信则只需要将sign_parameter中的校园网账号和网关密码替换为自己的即可。\n如果不是，则需要去浏览器打开开发者模式去找到对应是sign_parameter，并且将wlan_user_ip改成wlan_user_ip={get_ip()}，这样子就可以自动获取ip保证每次登录成功。\n","date":"11 May 2024","externalUrl":null,"permalink":"/python/tricks/autologin/bn%E5%92%8Cln%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E5%AF%B9%E6%AF%94/","section":"Python","summary":"","title":"校园网防断连（仅限suda，其它学校如果是网页验证登录也可以","type":"python"},{"content":" 也算是一篇对VIT注意力机制的改进，采用两步来对token进行稀疏化，是自动化的。\n其中图(a)是原始的注意力实现，其直接在全局范围内操作，导致高计算复杂性和大量内存占用；而对于图(b)-(d)，这些方法通过引入具有不同手工模式的稀疏注意力来减轻复杂性，例如局部窗口、轴向条纹和扩张窗口等；而图(e)则是基于可变形注意力通过不规则网格来实现图像自适应稀疏性；\n总的来说，作者认为以上这些方法大都是通过将 手工制作 和 与内容无关 的稀疏性引入到注意力机制来试图缓解这个问题。因此，本文通过双层路由(bi-level routing)提出了一种新颖的动态稀疏注意力(dynamic sparse attention )，以实现更灵活的计算分配和内容感知，使其具备动态的查询感知稀疏性，如图(f)所示。\n此外，基于该基础模块，本文构建了一个名为BiFormer的新型通用视觉网络架构。由于 BiFormer 以查询自适应的方式关注一小部分相关标记，而不会分散其他不相关标记的注意力，因此它具有良好的性能和高计算效率。最后，通过在图像分类、目标检测和语义分割等多项计算机视觉任务的实证结果充分验证了所提方法的有效性。\n本篇工作的核心方法：\n第一步：在粗区域级别上过滤掉最不相关的Q-K键值对向量，只保留一小部分路由区域。\n第二步：再在这些路由区域的并集中应用细粒度的token-to-token注意力机制 。\n","date":"8 May 2024","externalUrl":null,"permalink":"/paperreading/cvpr/biformer/","section":"Paper Reading","summary":"","title":"BiFormer: Vision Transformer with Bi-Level Routing Attention","type":"paperreading"},{"content":"","date":"8 May 2024","externalUrl":null,"permalink":"/python/imageprocessing/","section":"Python","summary":"","title":"Image Processing","type":"python"},{"content":"","date":"8 May 2024","externalUrl":null,"permalink":"/tags/imgprocess/","section":"Tags","summary":"","title":"ImgProcess","type":"tags"},{"content":"均使用plt库进行显示\n使用nibabel和MONAI库 # nibabel和MONAI加载nii格式图像时，其读取的维度均为（W,H,C），而plt.imshow显示图像二维灰度图像则是按照H,W进行显示的，因此会导致显示的图片出现旋转和翻折，与原图有很大不同。此时需要对读取的变量进行维度的转换。\n可以使用numpy的transpose对W,H进行交换，从而可以正常显示。\n代码如下（以nibabel举例）：\nimport nibabel as nib import matplotlib.pyplot as plt import numpy as np img = nib.load(r\u0026#39;E:\\dataset\\old\\RP\\RP_100\\all\\1\\1-P-L-O.nii.gz\u0026#39;) img_arr = img.get_fdata() # 显示图像 fig, axes = plt.subplots(2, 1) print(img_arr.shape) # 显示第一个图像 axes[0].imshow(img_arr[:,:,0], cmap=\u0026#39;gray\u0026#39;) axes[0].set_title(\u0026#39;Original Image\u0026#39;) axes[0].axis(\u0026#39;off\u0026#39;) img_arr_transposed = np.transpose(img_arr, (1, 0, 2)) print(img_arr_transposed.shape) # 显示第二个图像 axes[1].imshow(img_arr_transposed[:,:,0], cmap=\u0026#39;gray\u0026#39;) axes[1].set_title(\u0026#39;Transposed Image\u0026#39;) axes[1].axis(\u0026#39;off\u0026#39;) plt.show() 使用SimpleITK库 # SimpleITK库读取nii图像时，其通道为(C,H,W)，此时只需要选择对应通道进行切片输入plt.imshow即可正确显示图像。\n代码如下：\nimport SimpleITK as sitk import matplotlib.pyplot as plt # 读取NIfTI图像 image_path = r\u0026#39;E:\\dataset\\old\\RP\\RP_100\\all\\90\\90-P-L-O.nii.gz\u0026#39; sitk_image = sitk.ReadImage(image_path) # 将SimpleITK图像转换为NumPy数组 image_array = sitk.GetArrayFromImage(sitk_image) print(image_array.shape) # 显示图像的一个切片 plt.imshow(image_array[0, :, :], cmap=\u0026#39;gray\u0026#39;) # 显示第一个切片 plt.title(\u0026#39;NIfTI Image with SimpleITK\u0026#39;) plt.colorbar() plt.show() ","date":"8 May 2024","externalUrl":null,"permalink":"/python/imageprocessing/nii.gz%E5%9B%BE%E5%83%8F%E7%9A%84%E8%AF%BB%E5%8F%96%E4%B8%8E%E6%98%BE%E7%A4%BA%E8%B5%B0%E8%BF%87%E7%9A%84%E5%9D%91/nii.gz%E5%9B%BE%E5%83%8F%E7%9A%84%E8%AF%BB%E5%8F%96%E4%B8%8E%E6%98%BE%E7%A4%BA%E8%B5%B0%E8%BF%87%E7%9A%84%E5%9D%91/","section":"Python","summary":"","title":"nii.gz格式图像的读取与显示走过的坑","type":"python"},{"content":" SQL概述 # SQL简介 # 英文：Structured Query Language，简称 SQL 结构化查询语言，一门操作关系型数据库的编程语言 定义操作所有关系型数据库的统一标准 通用语法 # SQL 语句可以单行或多行书写，以分号结尾。\nMySQL 数据库的 SQL 语句不区分大小写，关键字建议使用大写。\n注释\n单行注释: \u0026ndash; 注释内容 或 #注释内容(MySQL 特有) 注意：使用\u0026ndash; 添加单行注释时，\u0026ndash;后面一定要加空格，而#没有要求。\n多行注释: /* 注释 */ SQL分类 # DDL(Data Definition Language) ： 数据定义语言，用来定义数据库对象：数据库，表，列等\nDDL简单理解就是用来操作数据库，表等\nDML(Data Manipulation Language) 数据操作语言，用来对数据库中表的数据进行增删改\nDML简单理解就对表中数据进行增删改\nDQL(Data Query Language) 数据查询语言，用来查询数据库中表的记录(数据)\nDQL简单理解就是对数据进行查询操作。从数据库表中查询到我们想要的数据。\nDCL(Data Control Language) 数据控制语言，用来定义数据库的访问权限和安全级别，及创建用户\nDML简单理解就是对数据库进行权限控制。比如我让某一个数据库表只能让某一个用户进行操作等。\n注意： 最常操作的是 DML 和 DQL ，因为开发中最常操作的就是数据。\nDDL # 操作数据库 # 操作 SQL 语句 说明 查询所有数据库 SHOW DATABASES; 列出所有数据库。 创建数据库 CREATE DATABASE 数据库名称; 创建新数据库。 创建数据库（判断） CREATE DATABASE IF NOT EXISTS 数据库名称; 如果数据库不存在，则创建。 删除数据库 DROP DATABASE 数据库名称; 删除指定数据库。 删除数据库（判断） DROP DATABASE IF EXISTS 数据库名称; 如果数据库存在，则删除。 使用数据库 USE 数据库名称; 选择当前操作的数据库。 查看当前使用数据库 SELECT DATABASE(); 查看当前使用的数据库名称。 操作表 # 对表进行操作主要包括增（Create）、删（Delete）、改（Update）、查（Retrieve）等。\n查询表 # 操作 SQL 语句 说明 查询当前数据库下所有表名称 SHOW TABLES; 列出当前数据库下的所有表。 查询表结构 DESC 表名称; 查看指定表的结构，包括字段名称、类型等信息。 创建表 # 操作 SQL 语句 说明 创建表 CREATE TABLE 表名 ( 字段名1 数据类型1, 字段名2 数据类型2, ... 字段名n 数据类型n ); 创建一张新的表。 创建示例 sql\u0026lt;br\u0026gt;CREATE TABLE tb_user (id INT, username VARCHAR(20), password VARCHAR(32)); 创建 tb_user 表，包含三个字段：id、username、password。 注意 最后一行字段定义不应添加逗号（,）。 若加上逗号，可能导致语法错误。 数据类型 # MySQL 支持的数据类型分为三大类：\n类型 数据类型 说明 数值 TINYINT 小整数型，占 1 字节。 INT 大整数型，占 4 字节。 DOUBLE(总长度,小数位数) 浮点数型。 日期 DATE 只包含年月日，例如：2023-01-01。 DATETIME 包含年月日时分秒，例如：2023-01-01 10:30:00。 字符串 CHAR(n) 定长字符串，长度固定为 n，即使实际存储数据长度不足 n，也会占用 n 个字符空间。 VARCHAR(n) 变长字符串，最大长度 n。实际存储多少字符，空间占用就为多少。 删除表 # 操作 SQL 语句 说明 删除表 DROP TABLE 表名; 删除指定表。 删除表（判断） DROP TABLE IF EXISTS 表名; 删除表前先判断是否存在，避免错误。 修改表 # 操作 SQL 语句 说明 修改表名 ALTER TABLE 表名 RENAME TO 新的表名; 修改表的名称 添加一列 ALTER TABLE 表名 ADD 列名 数据类型; 在表中添加一个新的字段。 修改字段数据类型 ALTER TABLE 表名 MODIFY 列名 新数据类型; 修改字段的数据类型。 修改字段名和类型 ALTER TABLE 表名 CHANGE 列名 新列名 新数据类型; 修改字段名和字段类型。 删除列 ALTER TABLE 表名 DROP 列名; 删除表中的指定列。 DML # DML（Data Manipulation Language）主要用于对数据进行增（INSERT）、删（DELETE）、改（UPDATE）操作。\n添加数据 # 操作 SQL 语句 说明 给指定列添加数据 INSERT INTO 表名 (列名1, 列名2, …) VALUES (值1, 值2, …); 向表的指定列插入一行数据。 给所有列添加数据 INSERT INTO 表名 VALUES (值1, 值2, …); 向表中插入一行数据，所有列都需要提供值。 批量添加数据（指定列） INSERT INTO 表名 (列名1, 列名2, …) VALUES (值1, 值2, …), (值1, 值2, …), …; 向表的指定列批量插入多行数据。 批量添加数据（所有列） INSERT INTO 表名 VALUES (值1, 值2, …), (值1, 值2, …), …; 向表中批量插入多行数据，所有列都需要提供值。 查询表中的所有数据 SELECT * FROM 表名; 查询表中的所有数据。 修改数据 # 操作 SQL 语句 说明 修改表数据 UPDATE 表名 SET 列名1=值1, 列名2=值2, … [WHERE 条件]; 更新表中数据。WHERE 子句用于限制更新范围。 修改表中所有数据 UPDATE 表名 SET 列名=值; 如果不加 WHERE 条件，将更新表中的所有数据。 注意：\n条件：建议在 UPDATE 语句中始终使用 WHERE 子句，否则可能会导致整个表的数据被修改。 删除数据 # 操作 SQL 语句 说明 删除指定条件的数据 DELETE FROM 表名 WHERE 条件; 删除满足条件的数据。 删除所有数据 DELETE FROM 表名; 如果不加 WHERE 条件，将删除表中的所有数据。 DQL # SQL 查询操作主要分为基础查询、条件查询、排序查询、聚合查询、分组查询、分页查询等。\n完整语法：\nSELECT 字段列表 FROM 表名列表 WHERE 条件列表 GROUP BY 分组字段 HAVING 分组后条件 ORDER BY 排序字段 LIMIT 分页限定 基础查询 # 操作 SQL 语句 说明 查询指定字段 SELECT 字段列表 FROM 表名; 查询表中指定字段的数据。 查询所有字段 SELECT * FROM 表名; 查询表中的所有字段和数据（不建议使用 *）。 去重查询 SELECT DISTINCT 字段列表 FROM 表名; 查询数据并去除重复记录。 使用别名（AS 可省略） SELECT 字段名 AS 别名 FROM 表名; 对查询结果的字段进行重命名。 条件查询 # 操作 SQL 语句 说明 使用条件查询 SELECT 字段列表 FROM 表名 WHERE 条件列表; 使用 WHERE 子句指定查询条件。 条件查询（比较运算符） SELECT * FROM 表名 WHERE age \u0026gt; 20; 使用比较运算符（如 \u0026gt;, \u0026gt;=, = 等）。 范围查询（AND 组合） SELECT * FROM 表名 WHERE age \u0026gt;= 20 AND age \u0026lt;= 30; 使用 AND 组合条件进行范围限制。 范围查询（BETWEEN） SELECT * FROM 表名 WHERE age BETWEEN 20 AND 30; 使用 BETWEEN ... AND 进行范围查询。 日期范围查询 SELECT * FROM 表名 WHERE hire_date BETWEEN '1998-09-01' AND '1999-09-01'; 查询在指定日期范围内的数据。 条件查询（IN） SELECT * FROM 表名 WHERE age IN (18, 20, 22); 使用 IN 关键字匹配多个值。 查询 NULL 值 SELECT * FROM 表名 WHERE 字段 IS NULL; 查询字段值为 NULL 的数据。 查询非 NULL 值 SELECT * FROM 表名 WHERE 字段 IS NOT NULL; 查询字段值不为 NULL 的数据。 模糊查询 # 操作 SQL 语句 说明 使用 LIKE 关键字 SELECT * FROM 表名 WHERE 字段 LIKE '马%'; 使用 LIKE 进行模糊匹配。 匹配单个任意字符 _ SELECT * FROM 表名 WHERE 字段 LIKE '_花%'; 使用 _ 表示单个任意字符占位。 匹配多个任意字符 % SELECT * FROM 表名 WHERE 字段 LIKE '%德%'; 使用 % 表示多个任意字符占位。 排序查询 # 操作 SQL 语句 说明 使用排序 `SELECT 字段列表 FROM 表名 ORDER BY 字段名 [ASC DESC];` 按单字段升序排序 SELECT * FROM 表名 ORDER BY age ASC; 默认按升序（ASC）排列。 按单字段降序排序 SELECT * FROM 表名 ORDER BY math DESC; 使用 DESC 进行降序排列。 多字段排序 SELECT * FROM 表名 ORDER BY math DESC, english ASC; 多条件排序时，优先级由前至后。 聚合查询 # 操作 SQL 语句 说明 统计记录数量 SELECT COUNT(*) FROM 表名; 统计表中的总记录数。 统计指定字段数量 SELECT COUNT(字段名) FROM 表名; 统计非 NULL 值的记录数。 最大值查询 SELECT MAX(字段名) FROM 表名; 查询字段的最大值。 最小值查询 SELECT MIN(字段名) FROM 表名; 查询字段的最小值。 求和 SELECT SUM(字段名) FROM 表名; 计算字段的总和。 平均值查询 SELECT AVG(字段名) FROM 表名; 计算字段的平均值。 分组查询 # 操作 SQL 语句 说明 分组查询 SELECT 分组字段, 聚合函数 FROM 表名 GROUP BY 分组字段; 按分组字段进行分组查询。 分组条件过滤 SELECT 分组字段, 聚合函数 FROM 表名 GROUP BY 分组字段 HAVING 条件; 使用 HAVING 对分组结果进行过滤。 区别：\nWHERE：用于分组前的条件过滤，不支持聚合函数。 HAVING：用于分组后的结果过滤，可以使用聚合函数。 分页查询 # 操作 SQL 语句 说明 分页查询 SELECT 字段列表 FROM 表名 LIMIT 起始索引, 查询条目数; 按分页查询数据。 计算起始索引 起始索引 = (当前页码 - 1) * 每页显示条数 起始索引从 0 开始。 查询第 1 页数据 SELECT * FROM 表名 LIMIT 0, 3; 每页显示 3 条数据，查询第 1 页。 查询第 2 页数据 SELECT * FROM 表名 LIMIT 3, 3; 每页显示 3 条数据，查询第 2 页。 约束（Constraints） # 约束是数据库管理中用于保证数据 正确性、有效性 和 完整性 的规则。 约束的作用是在数据录入和修改时防止不符合要求的数据进入数据库。\n例如：某列不能为 NULL、某列值不能重复、外键约束关联两张表等。 约束的分类与概念 # 约束类型 关键字 功能描述 非空约束 NOT NULL 保证列中数据不能为 NULL。 唯一约束 UNIQUE 保证列中数据唯一，不重复。 主键约束 PRIMARY KEY 唯一标识一行数据，要求非空且唯一。每张表只能有一个主键。 检查约束 CHECK 确保列中的值符合某一条件（MySQL 不支持）。 默认约束 DEFAULT 在保存数据时，如果未指定值，则使用默认值。 外键约束 FOREIGN KEY 建立表与表之间的关联，保证数据一致性和完整性。 非空约束 # 概念： 非空约束用于保证列中的数据不能为 NULL 值。 操作 SQL 语句 说明 添加非空约束 CREATE TABLE 表名 (字段名 数据类型 NOT NULL, …); 创建表时添加非空约束。 ALTER TABLE 表名 MODIFY 字段名 数据类型 NOT NULL; 建表后添加非空约束。 删除非空约束 ALTER TABLE 表名 MODIFY 字段名 数据类型; 删除非空约束。 唯一约束 # 概念： 唯一约束用于保证列中数据不能重复。 操作 SQL 语句 说明 添加唯一约束 CREATE TABLE 表名 (字段名 数据类型 UNIQUE, …); 创建表时添加唯一约束。 ALTER TABLE 表名 MODIFY 字段名 数据类型 UNIQUE; 建表后添加唯一约束。 删除唯一约束 ALTER TABLE 表名 DROP INDEX 字段名; 删除唯一约束。 主键约束 # 概念： 主键是表中唯一标识一行数据的字段，必须 唯一 且 非空。\n每张表只能有一个主键。 操作 SQL 语句 说明 添加主键约束 CREATE TABLE 表名 (字段名 数据类型 PRIMARY KEY, …); 创建表时添加主键约束。 ALTER TABLE 表名 ADD PRIMARY KEY (字段名); 建表后添加主键约束。 删除主键约束 ALTER TABLE 表名 DROP PRIMARY KEY; 删除主键约束。 默认约束 # 概念： 默认约束在保存数据时，若未指定值，则使用默认值。 操作 SQL 语句 说明 添加默认约束 CREATE TABLE 表名 (字段名 数据类型 DEFAULT 默认值, …); 创建表时添加默认约束。 ALTER TABLE 表名 ALTER 字段名 SET DEFAULT 默认值; 建表后添加默认约束。 删除默认约束 ALTER TABLE 表名 ALTER 字段名 DROP DEFAULT; 删除默认约束。 外键约束 # 概念： 外键用于建立表与表之间的关联，保证数据的一致性。\n外键字段必须引用另一表的主键。 操作 SQL 语句 说明 添加外键约束 CREATE TABLE 表名 (字段名 数据类型, CONSTRAINT 外键名 FOREIGN KEY (字段名) REFERENCES 主表(主键)); 创建表时添加外键约束。 ALTER TABLE 表名 ADD CONSTRAINT 外键名 FOREIGN KEY (字段名) REFERENCES 主表(主键); 建表后添加外键约束。 删除外键约束 ALTER TABLE 表名 DROP FOREIGN KEY 外键名; 删除外键约束。 数据库设计 # 数据库设计是根据业务系统的需求，结合数据库管理系统（DBMS）的特点，为业务系统构建出最优的数据存储模型的过程。\n它包括 表结构 和 表与表之间的关联关系 的设计。主要解决的问题是：\n有哪些表？ 表里有哪些字段？ 表和表之间有什么关系？ 数据库设计的步骤 # 步骤 描述 需求分析 了解系统需要管理的数据及其特性。 逻辑设计 使用 ER 图（实体-关系图）建模，独立于具体数据库系统。 物理设计 将逻辑设计转换为具体数据库系统的物理结构。 维护设计 在后期添加新需求时建表或优化已有表结构。 表关系 # 表关系描述了不同数据表之间的关联方式，通常分为以下三种：\n一对一、一对多、多对多。\n一对一关系 # 描述 实现方式 一条记录在表 A 中只能关联表 B 中的一条记录，反之亦然。 在任意一方设置外键，并将外键列设置为 UNIQUE。 -- 创建用户详情表 CREATE TABLE tb_user_desc ( id INT PRIMARY KEY AUTO_INCREMENT, city VARCHAR(20), edu VARCHAR(10), income INT, status CHAR(2), des VARCHAR(100) ); -- 创建用户表，添加外键约束 CREATE TABLE tb_user ( id INT PRIMARY KEY AUTO_INCREMENT, photo VARCHAR(100), nickname VARCHAR(50), age INT, gender CHAR(1), desc_id INT UNIQUE, CONSTRAINT fk_user_desc FOREIGN KEY (desc_id) REFERENCES tb_user_desc (id) ); 一对多关系 # 描述 实现方式 表 A 的一条记录可以关联表 B 的多条记录，表 B 的每条记录只能关联表 A 的一条记录。 在多的一方（B 表）建立外键，指向一的一方（A 表）的主键。 -- 删除表 DROP TABLE IF EXISTS tb_emp; DROP TABLE IF EXISTS tb_dept; -- 创建部门表（主表） CREATE TABLE tb_dept ( id INT PRIMARY KEY AUTO_INCREMENT, dep_name VARCHAR(20), addr VARCHAR(20) ); -- 创建员工表（从表），添加外键约束 CREATE TABLE tb_emp ( id INT PRIMARY KEY AUTO_INCREMENT, name VARCHAR(20), age INT, dep_id INT, CONSTRAINT fk_emp_dept FOREIGN KEY (dep_id) REFERENCES tb_dept (id) ); 多对多关系 # 描述 实现方式 表 A 的一条记录可以关联表 B 的多条记录，反之亦然。 建立第三张 中间表，中间表包含两个外键，分别指向 A 表和 B 表的主键。 -- 删除表 DROP TABLE IF EXISTS tb_order_goods; DROP TABLE IF EXISTS tb_order; DROP TABLE IF EXISTS tb_goods; -- 创建订单表 CREATE TABLE tb_order ( id INT PRIMARY KEY AUTO_INCREMENT, payment DOUBLE(10,2), payment_type TINYINT, status TINYINT ); -- 创建商品表 CREATE TABLE tb_goods ( id INT PRIMARY KEY AUTO_INCREMENT, title VARCHAR(100), price DOUBLE(10,2) ); -- 创建中间表，添加外键约束 CREATE TABLE tb_order_goods ( id INT PRIMARY KEY AUTO_INCREMENT, order_id INT, goods_id INT, count INT, CONSTRAINT fk_order_id FOREIGN KEY (order_id) REFERENCES tb_order (id), CONSTRAINT fk_goods_id FOREIGN KEY (goods_id) REFERENCES tb_goods (id) ); 多表查询 # 多表查询指在一次查询中从多个数据表中获取所需的数据。多表查询的类型包括 连接查询 和 子查询。\n连接查询 # 连接查询用于在多个表之间建立关联，通过字段匹配获取相关数据。\n连接查询的分类：\n内连接：查询两个表中都存在关联数据的记录（交集）。 外连接：包括左外连接和右外连接。 左外连接：查询左表的所有数据及与右表的交集数据。 右外连接：查询右表的所有数据及与左表的交集数据。 内连接查询 # 操作 SQL 语句 说明 隐式内连接 SELECT * FROM 表1, 表2 WHERE 表1.字段 = 表2.字段; 使用 WHERE 条件限制，实现内连接。 显式内连接 SELECT * FROM 表1 [INNER] JOIN 表2 ON 表1.字段 = 表2.字段; 使用 JOIN 关键字，显式地进行内连接。 使用别名优化查询 SELECT t1.字段, t2.字段 FROM 表1 t1, 表2 t2 WHERE t1.字段 = t2.字段; 使用别名提高查询可读性。 -- 隐式内连接查询 SELECT emp.name, emp.gender, dept.dname FROM emp, dept WHERE emp.dep_id = dept.did; -- 显式内连接查询（INNER 可以省略） SELECT emp.name, emp.gender, dept.dname FROM emp INNER JOIN dept ON emp.dep_id = dept.did; 外连接查询 # 操作 SQL 语句 说明 左外连接 SELECT * FROM 表1 LEFT [OUTER] JOIN 表2 ON 表1.字段 = 表2.字段; 查询左表的所有数据和关联数据。 右外连接 SELECT * FROM 表1 RIGHT [OUTER] JOIN 表2 ON 表1.字段 = 表2.字段; 查询右表的所有数据和关联数据。 -- 左外连接 SELECT * FROM emp LEFT JOIN dept ON emp.dep_id = dept.did; -- 右外连接 SELECT * FROM emp RIGHT JOIN dept ON emp.dep_id = dept.did; 子查询 # 子查询是在一个查询中嵌套另一个查询。子查询可以用作条件值或虚拟表。\n子查询分类：\n单行单列子查询：返回一行一列的数据，通常用于条件比较（如 =、\u0026gt;、\u0026lt;）。 多行单列子查询：返回多行一列的数据，使用 IN 关键字进行匹配。 多行多列子查询：返回多行多列的数据，作为虚拟表使用。 操作 SQL 语句 说明 单行单列子查询 SELECT * FROM 表 WHERE 字段 \u0026gt; (子查询语句); 使用子查询返回的单一值进行条件判断。 多行单列子查询 SELECT * FROM 表 WHERE 字段 IN (子查询语句); 使用子查询返回的多行值进行条件匹配。 子查询作为虚拟表 SELECT 列名 FROM (子查询语句) AS 虚拟表; 使用子查询的结果作为虚拟表。 -- 查询工资高于“猪八戒”的员工信息 SELECT * FROM emp WHERE salary \u0026gt; (SELECT salary FROM emp WHERE name = \u0026#39;猪八戒\u0026#39;); -- 查询部门编号在子查询返回的范围内的员工信息 SELECT * FROM emp WHERE dep_id IN (SELECT did FROM dept); 事务 # 事务（Transaction） 是一组数据库操作的集合，这些操作要么全部成功，要么全部失败。事务的目的是确保数据库在出现错误或异常时，数据的一致性和完整性。\n事务操作语法 # 操作 SQL 语句 说明 开启事务 START TRANSACTION; 或 BEGIN; 开始一个事务。 提交事务 COMMIT; 提交事务，确认所有操作成功。 回滚事务 ROLLBACK; 回滚事务，撤销所有操作。 查看自动提交状态 SELECT @@autocommit; 查询事务是否为自动提交模式（1：自动提交）。 设置手动提交 SET @@autocommit = 0; 禁用自动提交，改为手动提交事务。 事务的四大特性（ACID） # 特性 描述 原子性 事务是不可分割的操作单元，所有操作要么全部成功，要么全部失败。 一致性 事务完成时，数据库状态必须保持一致。 隔离性 多个事务并发执行时，彼此之间的操作是隔离的，不会互相干扰。 持久性 一旦事务提交或回滚，数据的变更将永久保存到数据库中。 隔离级别 # 隔离级别 描述 可能出现的问题 读未提交（Read Uncommitted） 事务可以读取到其他未提交事务的修改。 脏读、不可重复读、幻读。 读已提交（Read Committed） 事务只能读取到已提交事务的修改。 不可重复读、幻读。 可重复读（Repeatable Read） 在同一个事务中多次读取同一数据时，结果保持一致（MySQL 默认级别）。 幻读。 序列化（Serializable） 所有事务串行执行，完全隔离。 性能较低，可能出现大量锁等待。 脏读、不可重复读、幻读概念：\n现象 描述 脏读（Dirty Read） 一个事务读取了另一个未提交事务修改的数据，可能导致读取到无效或错误的数据。 不可重复读（Non-repeatable Read） 一个事务多次读取同一行数据，每次读取的结果可能不同（其他事务可能在中途修改了该行数据）。 幻读（Phantom Read） 一个事务两次读取符合条件的数据集合，第二次读取时集合中多了或少了行数据（其他事务可能增删了数据）。 不可重复读和幻读的区别：\n现象 不可重复读 幻读 操作对象 单条记录 满足条件的记录范围 表现 同一条记录在两次读取中发生了修改或删除，导致结果不一致 第一次查询的结果集在第二次查询时新增或减少了行记录 来源 其他事务修改或删除了该记录 其他事务插入或删除了符合条件的新记录 解决方式 Repeatable Read 隔离级别可以防止 Serializable 隔离级别可以完全防止 设置事务隔离级别 # 操作 SQL 语句 查看当前事务隔离级别 SELECT @@transaction_isolation; 设置事务隔离级别为读已提交 SET TRANSACTION ISOLATION LEVEL READ COMMITTED; 设置事务隔离级别为可重复读 SET TRANSACTION ISOLATION LEVEL REPEATABLE READ; 设置事务隔离级别为序列化 SET TRANSACTION ISOLATION LEVEL SERIALIZABLE; 自动提交 # 自动提交：MySQL 默认情况下，事务是自动提交的。即每条 SQL 语句在执行完成后，事务会自动提交。\n查看自动提交状态：\nSELECT @@autocommit; 关闭自动提交：\nSET @@autocommit = 0; 恢复自动提交：\nSET @@autocommit = 1; ","externalUrl":null,"permalink":"/java/javaweb/mysql/mysql/","section":"Java","summary":"","title":"1.Mysql","type":"java"},{"content":" JDBC 概述 # Java 数据库连接（JDBC，Java Database Connectivity）是一套用于操作数据库的 Java API，它为 Java 应用程序提供了统一的数据库访问接口。通过 JDBC，开发者可以编写与具体数据库无关的代码，实现数据库的连接、操作以及数据处理，从而大大简化了数据库编程的复杂性。\nJDBC 支持标准 SQL 命令，并提供了处理结果集、事务管理以及批处理等功能，使得在 Java 应用中进行数据库操作变得灵活且高效。\n不过这部分太复杂，后续只需要使用MyBatis就可以了。\nJDBC 编写代码步骤 # 加载 JDBC 驱动 在与数据库建立连接之前，需要加载相应数据库的 JDBC 驱动类。早期版本需要显式加载驱动类（例如使用 Class.forName），但在新版 JDBC 中通常通过驱动自动注册机制完成。\nClass.forName(\u0026#34;com.mysql.jdbc.Driver\u0026#34;); 建立数据库连接 使用 DriverManager.getConnection(url, username, password) 方法与数据库建立连接。这里需要提供数据库的 URL、用户名以及密码。成功建立连接后会返回一个 Connection 对象。\nConnection conn = DriverManager.getConnection(url, username, password); 创建 SQL 语句对象 通过 Connection 对象创建 Statement 或 PreparedStatement 对象。\nStatement 对象适用于执行静态 SQL 语句； PreparedStatement 对象适用于执行带参数的预编译 SQL 语句，具有更好的安全性（防止 SQL 注入）和性能优化。 String sql = “update…” ; Statement stmt = conn.createStatement(); 执行 SQL 语句 调用语句对象的 executeQuery、executeUpdate 或 execute 方法执行 SQL 语句，并获取执行结果。\n查询语句返回 ResultSet 对象； 更新、删除、插入等操作返回受影响的行数。\nstmt.executeUpdate(sql); 处理结果集 对于查询语句返回的 ResultSet 对象，可以通过遍历结果集来获取每一行的数据。常用方法包括 next()、getString()、getInt() 等。\n关闭资源 数据库操作完成后，需要依次关闭 ResultSet、Statement（或 PreparedStatement）以及 Connection 对象，释放数据库资源，避免资源泄露。\n完整示例\npublic class JDBCDemo { public static void main(String[] args) throws Exception { //1. 注册驱动 //Class.forName(\u0026#34;com.mysql.jdbc.Driver\u0026#34;); //2. 获取连接 String url = \u0026#34;jdbc:mysql://127.0.0.1:3306/db1\u0026#34;; String username = \u0026#34;root\u0026#34;; String password = \u0026#34;1234\u0026#34;; Connection conn = DriverManager.getConnection(url, username, password); //3. 定义sql String sql = \u0026#34;update xxx\u0026#34;; //4. 获取执行sql的对象 Statement Statement stmt = conn.createStatement(); //5. 执行sql int count = stmt.executeUpdate(sql);//受影响的行数 //6. 处理结果 System.out.println(count); //7. 释放资源 stmt.close(); conn.close(); } } JDBC 的几个 API 详解 # DriverManager # 作用： DriverManager 类用于管理一组 JDBC 驱动程序。它负责根据提供的数据库 URL 选择合适的驱动程序，并建立与数据库的连接。\n常用方法：\ngetConnection(String url, String user, String password) 根据数据库 URL 及用户凭据获取一个数据库连接。 registerDriver(Driver driver) 注册一个 JDBC 驱动程序（通常在驱动内部已经自动注册）。 注意事项： 早期需要显式加载驱动类，但在大多数现代应用中，只需在项目中引入对应数据库的 JDBC 驱动包即可，由驱动自动完成注册。\nConnection # 作用： Connection 接口代表与数据库的一个连接会话，是 JDBC 操作的核心对象。通过它可以创建 SQL 执行语句、管理事务以及获取数据库元数据。\n常用方法：\ncreateStatement() 创建一个 Statement 对象，用于执行静态 SQL 语句。 prepareStatement(String sql) 创建一个 PreparedStatement 对象，用于执行预编译 SQL 语句，可以防止SQL注入。 commit() 和 rollback() 用于管理事务的提交与回滚。 close() 关闭连接，释放资源。 注意事项： 应始终在操作结束后调用 close() 方法释放连接资源，防止数据库连接数耗尽。\nStatement # 作用： Statement 接口用于执行简单的 SQL 语句。适用于不带参数的静态 SQL 查询或更新操作。\n常用方法：\nexecuteQuery(String sql) 执行查询语句，返回一个 ResultSet 对象 executeUpdate(String sql) 执行更新操作（如 INSERT、UPDATE、DELETE），返回受影响的行数。 execute(String sql) 执行任意 SQL 语句，返回一个布尔值表示是否返回 ResultSet。 注意事项： 对于动态 SQL 或存在输入参数的情况，推荐使用 PreparedStatement 来增强安全性和性能。\nResultSet # 作用： ResultSet 对象存储了执行查询语句后返回的数据表数据。它允许按行逐步遍历查询结果，并获取每一列的值。\n常用方法：\nnext() 移动到结果集的下一行，初始时位于第一行之前。 getString(String columnLabel)、getInt(String columnLabel) 等 根据列名或列索引获取对应类型的数据。 close() 关闭 ResultSet 对象，释放相关资源。 注意事项： 读取数据时应确保 next() 返回 true 后再调用数据获取方法，否则可能会引发异常。\nPreparedStatement # 作用： PreparedStatement 接口是 Statement 的子接口，用于执行预编译的 SQL 语句。它支持带参数的查询和更新操作，有助于防止 SQL 注入并提升性能。\n常用方法：\nsetString(int parameterIndex, String x)、setInt(int parameterIndex, int x) 等 为预编译 SQL 语句中的参数占位符设置具体的值。 executeQuery() 执行查询操作，返回一个 ResultSet 对象。 executeUpdate() 执行更新操作，返回受影响的行数。 close() 关闭 PreparedStatement 对象，释放资源。 注意事项： 在批量操作中，PreparedStatement 可以复用预编译 SQL，提高效率；并且因为参数是分离绑定的，所以可以有效防止 SQL 注入攻击。\n","externalUrl":null,"permalink":"/java/javaweb/jdbc/jdbc/","section":"Java","summary":"","title":"2.JDBC","type":"java"},{"content":" Maven # Maven专门用于 Java 项目的构建、依赖管理以及项目标准化。它采用了**项目对象模型（POM，Project Object Model）**来描述项目结构、依赖关系和构建过程。简单来说，Maven 有以下几个主要特点：\n标准化项目结构：所有通过 Maven 构建的项目都遵循统一的目录结构，这样无论在 Eclipse、IntelliJ IDEA 还是其他 IDE 中，都能快速识别项目结构，降低了团队协作时的沟通成本。 标准化构建流程：Maven 定义了一套完整的构建生命周期，包含编译、测试、打包、安装、部署等各个阶段。开发者只需要执行一个简单的命令，Maven 就会自动按照生命周期顺序完成所有相关操作。 依赖管理机制：通过 Maven 坐标（groupId、artifactId、version），可以非常方便地声明项目所需的第三方依赖，Maven 会自动从中央仓库（或私服）下载对应的 jar 包并缓存到本地仓库。 Maven 的基本使用 # Maven 的使用主要体现在两个方面：命令行操作和构建生命周期的理解。\n常用命令 # 在命令行中使用 Maven 时，最常用的命令主要包括以下几个：\nmvn compile —— 编译项目 # 作用：将项目中的 Java 源代码编译成字节码文件（.class 文件）。\n执行过程\nMaven 会根据 POM 文件中的配置，将源码目录下的 Java 文件进行编译，生成的 class 文件会存放在 target/classes 目录下。 如果项目依赖某些外部 jar 包，Maven 会先去本地仓库查找相应的依赖，如果没有则会从中央仓库或配置的镜像（如阿里云镜像）下载后缓存到本地仓库，再进行编译。 示例\nmvn compile 执行后，命令行会显示编译过程以及可能的依赖下载信息。\nmvn clean —— 清理项目 # 作用：删除项目生成的所有构建文件，通常包括 target 目录下的所有文件。\n作用场景\n当你想从零开始重新构建项目，避免旧文件干扰时使用。 保持项目目录整洁，避免多次构建产生冗余文件。 示例\nmvn clean 执行后，项目中的 target目录会被删除，确保后续构建时不会受到旧文件的影响。\nmvn test —— 执行测试 # 作用：运行项目中编写的所有单元测试代码（通常在 src/test/java 目录下）。\n注意\nMaven 默认使用 Surefire 插件 来执行测试代码。 测试失败会导致整个构建失败。 示例\nmvn test 执行后，Maven 会编译测试代码并执行所有测试用例，并输出测试结果。\nmvn package —— 打包项目 # 作用：将编译后的代码、资源文件以及依赖打包成一个可执行的文件（如 jar 包或 war 包），便于部署或分发。\n过程\n该命令通常会先触发编译（compile）、测试（test）等步骤，然后将项目打包成目标文件（例如 jar 包）。 生成的包文件会存放在 target 目录下。 示例\nmvn package 执行后， target目录中生成的 jar 或 war 包。\nmvn install —— 安装项目 # 作用：除了执行 package 操作之外，还会将打包后的构件安装到本地仓库，以便其他项目引用该构件。\n场景\n当你开发了一个公共模块，需要在同一个系统中的其他 Maven 项目中使用时，使用 install 命令可以让这些项目通过 Maven 坐标来引用你安装的包。 示例\nmvn install 执行后，生成的 jar 包会被复制到本地仓库中，并根据 POM 中定义的坐标存放在相应的目录结构中。\n补充说明： 这些命令并非孤立使用，当你执行如 mvn install 时，实际上 Maven 会按照默认的构建生命周期依次执行所有前置阶段（如 compile、test、package 等）。\nMaven 生命周期 # Maven 定义了三个主要的生命周期，每个生命周期由若干个阶段（phase）组成。下面主要讲解最常用的 default（默认）生命周期，以及清理（clean）生命周期和站点（site）生命周期的基本概念。\n默认生命周期（default lifecycle） # 概念： 默认生命周期负责项目的构建过程，从源码编译、测试、打包到部署都在这一生命周期中进行。每个生命周期由多个阶段构成，执行时会按照定义的顺序依次执行。\n常见阶段：\nvalidate：验证项目是否正确且所有必要信息是否齐全。 compile：编译项目源码（将 src/main/java 下的代码编译成字节码）。 test：执行单元测试，验证编译后的代码质量。 package：将编译后的代码打包为可发布的格式（如 jar、war）。 verify：运行集成测试，确保包的质量符合标准（有时结合自动化测试）。 install：将构建好的包安装到本地仓库，以便于其他项目引用。 deploy：将构建好的包部署到远程仓库，以便共享给其他开发者或团队。 执行顺序：\n当你运行一个较高级别的目标命令时（如\nmvn install ），Maven 会自动执行这个生命周期中从前到后所有必要的阶段。例如：\n执行 mvn package 时，Maven 实际上会先执行 validate、compile、test 等阶段，最后再执行 package。 执行 mvn install 时，Maven 会先执行 package（及之前所有阶段），然后再执行 install。 示例说明：\n执行 mvn install 的完整过程： validate：检查 pom.xml 文件中的必要信息是否存在。 compile：将源码编译成字节码，生成到 target/classes。 test：执行测试代码（在 src/test/java 中），确保代码逻辑正确。 package：将编译后的文件打包成 jar 文件，存放在 target 目录下。 install：将 jar 包安装到本地仓库，使其他 Maven 项目可以通过坐标引用该包。 注意：如果某个阶段执行失败（例如单元测试失败），默认情况下整个构建流程会中止，后续阶段不会执行。这可以帮助开发者及时发现问题。 Clean 生命周期 # 概念： Clean 生命周期专门用于清理项目目录。其主要目的是删除之前构建过程中产生的文件（如 target 目录），从而保证每次构建都是从干净的环境开始。\n常见阶段：\npre-clean：在清理前执行的一些准备工作。 clean：删除生成的构建文件，如 target 目录。 post-clean：清理后的后续工作（一般使用较少）。 示例：\nmvn clean 该命令会执行 clean 生命周期，删除之前构建生成的所有文件，为下一次构建提供一个干净的环境。\nSite 生命周期 # 概念： Site 生命周期主要用于生成项目站点报告，比如项目文档、测试报告、代码覆盖率报告等。虽然日常开发中用得较少，但在需要生成项目详细文档和报告时非常有用。\n常见阶段：\npre-site：在生成站点前的一些准备工作。 site：生成项目站点及相关报告。 post-site：站点生成后的后续处理。 site-deploy：将生成的站点部署到指定服务器或位置。 示例：\nmvn site 执行后，Maven 会根据 POM 中的配置生成项目站点，输出结果通常在 target/site 目录下。\n依赖管理 # 在开发过程中，经常需要使用第三方库（如数据库驱动、日志框架、测试框架等），传统开发方式需要手动下载 jar 包、配置 classpath 等，而 Maven 的依赖管理机制可以大大简化这一流程。\nMaven 坐标 # Maven 通过坐标来唯一标识一个构件（包括项目、插件、依赖等）。一个完整的坐标通常包含以下部分： groupId：定义项目所属的组织或公司，通常使用反向域名（例如：com.itheima）。 artifactId：定义项目或模块的名称（例如：order-service、goods-service）。 version：定义项目的版本号（例如：1.0.0）。 （有时还会包含 packaging 和 classifier，但在大多数情况下省略，默认 jar 包即为 jar） 例如，一个 Maven 坐标可能是：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.28\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这段配置告诉 Maven，当项目需要使用 MySQL 驱动时，它会根据这个坐标从仓库中下载对应版本的 jar 包。\nPOM 文件 # 在 Maven 项目中，所有依赖都在项目根目录下的 pom.xml 文件中配置。基本结构如下：\n\u0026lt;project\u0026gt; ... \u0026lt;dependencies\u0026gt; \u0026lt;!-- 声明第一个依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.22\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 声明第二个依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.13.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 可以声明更多依赖 --\u0026gt; \u0026lt;/dependencies\u0026gt; ... \u0026lt;/project\u0026gt; 在添加或修改依赖后，通常需要刷新 Maven 工程，使新的依赖配置生效。\n在 pom.xml 中 按 alt + insert，选择 Dependency，可以快捷引入坐标。\n依赖作用域（Scope） # 通过设置依赖的 \u0026lt;scope\u0026gt; 标签，可以控制该依赖在项目中的使用范围。主要作用域及其含义如下：\n依赖范围（Scope） 编译时 测试时 运行时 常见示例 compile 是 是 是 大部分常规依赖，如日志框架（Logback） provided 是 是 否 容器提供的依赖，如 servlet-api runtime 否 是 是 JDBC 驱动、ORM 框架依赖 test 否 是 否 单元测试库，如 junit system 是 是 否 本地文件系统中存在的 jar（较少使用） compile：默认范围，所有环境（编译、测试、运行）都可使用。 provided：编译和测试时需要，但运行时由容器或其他机制提供。例如，开发 Web 应用时 servlet API 通常由 Web 服务器（如 Tomcat）提供，所以不需要打包到最终的部署包中。 runtime：运行时需要，编译时不需要。例如 JDBC 驱动，编译时只需要接口定义，而具体实现运行时加载。 test：仅在测试阶段使用，例如 JUnit、Mockito 等测试框架。 system：类似于 provided，但需要显式指定 jar 包路径。由于需要手动维护，使用较少。 示例：声明 JUnit 依赖仅在测试环境中使用\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.13.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 在这种配置下，当执行 mvn test 时，JUnit 会被加载；而在编译或打包生成最终产品时，不会将 JUnit 包含进去。\n依赖管理的优势 # 自动下载和更新：开发者只需在 pom.xml 中声明依赖，Maven 会自动从中央仓库或配置的镜像（如阿里云仓库）下载依赖 jar 包，并存放到本地仓库，避免手动下载和复制文件。 统一版本管理：对于多个模块的项目，可以在父 POM 中统一声明依赖版本，确保各模块使用一致的库版本，避免冲突。 传递性依赖：如果一个依赖本身也声明了其他依赖（传递性依赖），Maven 会自动解析并将其加入项目的构建中，这极大简化了依赖管理的复杂度。 范围控制：通过依赖作用域可以精准控制依赖在不同阶段的可见性，避免不必要的依赖加载到最终产品中。 综合示例 # 假设我们有一个简单的 Maven 项目，其 pom.xml 内容如下：\n\u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;!-- 项目的坐标信息 --\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;my-app\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt; \u0026lt;!-- 依赖管理 --\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- Spring 核心库，使用默认的 compile 作用域 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.22\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- JUnit，仅在测试时使用 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.13.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; 构建过程示例 编译：在命令行执行 mvn compile，Maven 根据 pom.xml 编译 src/main/java 下的源码，并将生成的 class 文件放入 target/classes 目录中。 测试：执行 mvn test，Maven 编译测试代码（src/test/java）并运行所有测试用例，利用 JUnit 进行单元测试。 打包：执行 mvn package，在测试通过后，Maven 将所有编译后的文件打包成一个 jar 文件存放在 target 目录中。 安装：执行 mvn install，除了上述步骤外，还会将生成的 jar 文件安装到本地仓库，供其他项目引用。 总结 # Maven 简介：Maven 是一款基于 POM 的项目构建工具，提供标准化的项目结构、构建流程和依赖管理机制。 Maven 的基本使用 常用命令如 compile、clean、test、package、install 分别对应编译、清理、测试、打包和安装步骤。 Maven 的默认生命周期定义了构建项目的各个阶段，从验证、编译、测试到打包、安装，每个命令都会自动依赖之前的阶段。 依赖管理 通过 Maven 坐标（groupId、artifactId、version）来唯一标识一个依赖，简化了第三方库的管理。 依赖作用域（compile、provided、runtime、test、system）可以控制依赖在不同阶段的可见性和加载，保证项目构建的灵活性和稳定性。 ","externalUrl":null,"permalink":"/java/javaweb/maven/maven/","section":"Java","summary":"","title":"3.Maven","type":"java"},{"content":"","externalUrl":null,"permalink":"/java/javaweb/mybatis/mybatis/","section":"Java","summary":"","title":"4.MyBatis","type":"java"},{"content":" A2FSeg\n是一篇关于多模态融合医学影像分割的文章。\n创新点在于：\n1.不要求每个模态都存在，可以只有1个也可以全都有，网络在融合阶段可以自适应。\n2.该网络具有两个阶段的特征融合，包括简单的平均融合和基于注意机制的自适应融合。两种融合技术都能够处理缺失模态的情况，并有助于改善分割结果。\n","externalUrl":null,"permalink":"/paperreading/miccai/a2fseg/","section":"Paper Reading","summary":"","title":"A2FSeg: Adaptive Multi-Modal Fusion Network for Medical Image Segmentation","type":"paperreading"},{"content":"","externalUrl":null,"permalink":"/python/algorithm/","section":"Python","summary":"","title":"Algorithm","type":"python"},{"content":"","externalUrl":null,"permalink":"/java/algorithm_java/","section":"Java","summary":"","title":"AlgorithmJava","type":"java"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":" Batch Normalization # 1.定义 # ​\tBatch Normalization（批次规范化）：在BN中，对于每个特征（通道），对整个批次（mini-batch）的数据进行规范化，以使其均值接近零，方差接近一。\n​\t计算每个特征的均值和方差，然后对批次中的每个样本进行规范化。\n​\t“对于一个拥有d维的输入x，我们将对它的每一个维度进行标准化处理。” 假设我们输入的x是RGB三通道的彩色图像，那么这里的d就是输入图像的channels即d=3，此时的BN就是对R,G,B三个通道进行处理。\n2.特点 # 规范化的对象：Batch normalization是基于每个批次（mini-batch）的数据进行规范化的。它计算每个特征的均值和方差，然后应用于整个批次中的每个样本。 数据依赖性：Batch Normalization具有数据依赖性，因为它依赖于每个批次的均值和方差。这意味着在训练和推理时，模型的输入数据分布会影响批次规范化的效果。 应用范围：Batch Normalization通常用于深度卷积神经网络（CNN）和全连接神经网络中。 训练和推理时：Batch Normalization在训练时使用批次的均值和方差进行规范化，但在推理时需要单独计算均值和方差，因此需要存储额外的参数。这可能导致在推理时的计算成本增加。换句话来说，就是BN需要存储更多的参数，并且在推理和计算时需要使用这些这些参数来进行数据的标准化，这一步是用来保证推理时的数据分布和训练时的数据分布总体相同，也就是保持一致性。此外，存储这些参数也可以增加网络效率。 Layer Normalization # 1.定义 # ​\tLayer Normalization（层规范化）：对于每个样本的每个特征，计算它们的均值和方差，然后对该样本内的所有特征进行规范化。\n​\t计算每个样本内的特征的均值和方差，然后对该样本内的所有特征进行规范化，以使其均值接近零，方差接近一。\n2.特点 # 规范化的对象：Layer normalization是基于每个样本的特征进行规范化的。它计算每个特征的均值和方差，然后应用于单个样本中的每个特征。 数据依赖性：Layer Normalization不具有数据依赖性，因为它是基于单个样本内的特征计算均值和方差。这使得层规范化在不同样本之间更加稳定，不受输入分布的影响。 应用范围：Layer Normalization通常用于RNN和Transformer中。 训练和推理时：Layer Normalization在训练和推理时都使用样本内的均值和方差，因此在推理时不需要额外的计算和存储开销。 ","externalUrl":null,"permalink":"/python/dataprocessing/bn%E5%92%8Cln%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E5%AF%B9%E6%AF%94/bn%E5%92%8Cln%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E5%AF%B9%E6%AF%94/","section":"Python","summary":"","title":"BN和LN的区别与对比","type":"python"},{"content":" 本文是结合CNN和Transformer来进行分类和分割，其中分割是次要任务用于辅助分类。\n其创新点在于：\n1.使用分割辅助分类，提升网络性能\n2.将分割的CNN捕获的归纳偏置信息与分类的Transformer的长距离信息直接结合送到分类层来进行分类\n3.对Swin Transformer进行了改进，再每个Block里加了Anatomy-Aware Attention (AAA)模块，如下图：\n此外，对于采用的CNN也有改进，如下图，也算是一个创新点，用于讲故事，比如可以捕获图片中更加细节的信息等等\n","externalUrl":null,"permalink":"/paperreading/miccai/hybridmt-estan/","section":"Paper Reading","summary":"","title":"Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network","type":"paperreading"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":" Linux # 进程管理与守护 # 两种方法:\n一种是日志重定向,但也会因为运行的终端被关闭而导致进程结束,好处是可以直接将日志保存下来;\n一种是使用screen保护会话,除非主动中止进程,否则无论是关闭终端还是ssh断连都不会影响程序运行.\n终端日志重定向 # # 日志重定向到train.log文件。即在你的命令后加上：\u0026gt; xxx.log 2\u0026gt;\u0026amp;1 python xxx.py \u0026gt; xxx.log 2\u0026gt;\u0026amp;1 # 实时查看日志 tail -f xxx.log Screen # 参考链接\n只要Screen本身没有终止，在其内部运行的会话都可以恢复。这一点对于远程登录的用户特别有用——即使网络连接中断，用户也不会失去对已经打开的命令行会话的控制。只要再次登录到主机上执行screen -r就可以恢复会话的运行。同样在暂时离开的时候，也可以执行分离命令detach，在保证里面的程序正常运行的情况下让Screen挂起（切换到后台）。\n该方法可以和日志重定向结合使用\n具体使用方法如下:\n创建screen终端\nscreen #随机名称 screen -S \u0026lt;作业名称\u0026gt; #这回指定screen作业的名称 创建完成后敲下回车即可进入一个和之前一模一样的终端,在这个终端运行命令是收到保护的.\n离开窗口\n使用ctl + a + d即可退出到原始端,并显示detached,代表这个会话只是离开并未退出。\n查看窗口和窗口名称\nscreen -ls 可以列出目前所有窗口的名称\n进入之前的窗口\nscreen -r \u0026lt;窗口名称\u0026gt; 彻底关闭开启的会话\n有程序则先 crl+c,再crl+d\n还有很多作用可以参考\u0026lt;参考链接\u0026gt;\nTMUX # 优点 # 可以在单个会话窗口中，同时分割成多个窗口，相当于之前访问的多个会话。对于同时运行多个命令行程序很有用。\n可以让新窗口\u0026quot;接入\u0026quot;已经存在的会话。\n支持窗口任意的垂直和水平拆分。\n在 TMUX 中，组件的层次结构和顺序为：\nSession（会话）：TMUX 的最顶层单元。一个会话可以包含多个窗口，可以理解为一个工作区，您可以在其中创建和管理多个任务。\nWindow（窗口）：每个会话可以包含多个窗口。每个窗口相当于一个独立的终端界面，类似于不同的标签页。窗口可以在同一个会话中切换。\nPane（面板）：每个窗口可以进一步分割为多个面板。面板是窗口内的分割区域，可以显示不同的命令行内容，相当于一个窗口的分屏操作。\nSession (会话) \u0026gt; Window (窗口) \u0026gt; Pane (面板)\n我一般直接一个session、一个window，然后在里面创建pane\n安装 # # Debian/Ubuntu sudo apt update sudo apt install tmux # CentOS/RHEL sudo yum install tmux # macOS (使用 Homebrew) brew install tmux 对于没有超级用户权限，没有macos的我来说，只能通过conda安装了\nconda install tmux 快速教程 # # 新建会话 tmux # 创建匿名会话 tmux new -s \u0026lt;session-name\u0026gt; # 新建一个指定名称的会话 # 分离会话 tmux detach # 将当前会话挂起，不关闭 # 查看会话 tmux ls # 列出所有会话 # 接入会话 tmux attach -t \u0026lt;session-id or session-name\u0026gt; # 通过会话 ID 或名称接入指定会话 # 重命名会话 tmux rename-session -t \u0026lt;session-id or old-name\u0026gt; \u0026lt;new-name\u0026gt; # 杀死会话 tmux kill-session -t \u0026lt;session-id or session-name\u0026gt; # 关闭指定会话 tmux kill-server # 关闭 TMUX 服务器，关闭所有会话 配置和状态 # # 重新加载配置文件 tmux source-file ~/.tmux.conf # 从配置文件重新加载配置 # 查看当前配置 tmux show-options -g # 显示 TMUX 的全局选项配置 tmux show-window-options -g # 显示窗口的全局选项配置 tmux show-options -s # 显示服务器配置 # 列出键绑定 tmux list-keys # 查看当前所有键绑定 # 列出所有 TMUX 命令 tmux list-commands # 显示 TMUX 支持的所有命令 功能 命令 新建会话 tmux new -s session名 -n 窗口名 查看已创建的会话 tmux ls attach到已有会话 tmux attach/at -t xxx 挂起会话 tmux detach 直接退出会话 exit 关闭指定会话 tmux kill-session -t 会话名 重命名当前窗口 tmux rename-window -t 窗口编号 新窗口名 水平分割面板 tmux split-window -h 垂直分割面板 tmux split-window -v 以下是 TMUX 中常用的快捷键：\n功能 快捷键 新建窗口 Ctrl-b c 切换到下一个窗口 Ctrl-b n 切换到上一个窗口 Ctrl-b p 指定窗口跳转 Ctrl-b 数字 水平分割窗口 Ctrl-b % 垂直分割窗口 Ctrl-b \u0026quot; 关闭当前窗口 Ctrl-b \u0026amp; 关闭当前面板 Ctrl-b x 切换面板 Ctrl-b o 调整面板大小 Ctrl-b，然后使用方向键调整 查看窗口列表 Ctrl-b w 将面板上下翻滚 Ctrl-b [ 退出滚动模式 q（在滚动模式中） 切换到上一个会话 Ctrl-b ( 切换到下一个会话 Ctrl-b ) 挂起会话 Ctrl-b d 文件和目录管理 # ","externalUrl":null,"permalink":"/notes/cheetsheet/","section":"Notes","summary":"","title":"CheetSheet","type":"notes"},{"content":"","externalUrl":null,"permalink":"/python/dataprocessing/","section":"Python","summary":"","title":"Data Processing","type":"python"},{"content":"","externalUrl":null,"permalink":"/tags/dataaugment/","section":"Tags","summary":"","title":"DataAugment","type":"tags"},{"content":" Drop out和Drop path的区别与作用 # 两者的提出都是为了提升网络性能，提升网络泛化性，防止网络出现过拟合等情况而使用的一种正则化的方法。\n其区别在于drop out 是使得一些网络神经元进行失活，常用于全连接层。而drop path常用于resnet等并行连接的网络中，使得其中一条网络路径完全失活，以resnet举例，就是只保留残差连接，而主路径的输入为0，即失活，此时Xi+1 = Xi。\n下面为代码示例：\nimport torch import torch.nn as nn def drop_path(x, drop_prob: float = 0., training: bool = False): if drop_prob == 0. or not training: return x keep_prob = 1 - drop_prob shape = (x.shape[0],) + (1,) * (x.ndim - 1) # work with diff dim tensors, not just 2D ConvNets random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device) random_tensor.floor_() # binarize output = x.div(keep_prob) * random_tensor return output x = torch.ones(2, 3, 2, 2) print(x) output = drop_path(x, drop_prob=0.5, training=True) output dropout = nn.Dropout(p=0.5) print(dropout(x)) 由代码示例可知，drop out失活了部分神经元，使其输入部分为0，输出自然也为0；而drop path使得一整个输入为0，即失活一整条神经路径。\n","externalUrl":null,"permalink":"/python/dataprocessing/dropout-and-droppath/dropout-and-droppath/","section":"Python","summary":"","title":"DropOut and DropPath","type":"python"},{"content":" 门控注意力机制 # 门控注意力\nThe Gated Multimodal Unit (GMU) model is intended to be used as an internal unit in a neural network architecture whose purpose is to find an intermediate representation based on a combination of data from different modalities.\nGMU的提出是为了更好的融合多模态数据，让每个模态的数据得到自己的权重，从而更好的表示多模态数据的融合。\n其实现比较简单，基本是使用线性层和激活函数来进行模态权重的计算与分配。具体公式如上图所示，以两个模态融合为例，相关代码如下：\nimport torch import torch.nn as nn class GatedMultimodalUnit(nn.Module): def __init__(self, text_dim, image_dim, hidden_dim): super(GatedMultimodalUnit, self).__init__() self.text_linear = nn.Linear(text_dim, hidden_dim) self.image_linear = nn.Linear(image_dim, hidden_dim) self.gate_linear = nn.Linear(text_dim + image_dim, hidden_dim) def forward(self, text, image): text_repr = self.text_linear(text) image_repr = self.image_linear(image) gate = torch.sigmoid(self.gate_linear(torch.cat((text, image), dim=1))) fused_repr = gate * text_repr + (1 - gate) * image_repr return fused_repr 在《Pathomic Fusion: An Integrated Framework for Fusing Histopathology and Genomic Features for Cancer Diagnosis and Prognosis》这篇论文中就采用了门控注意力机制来进行多个模态的融合，其中包含两个图像数据（使用CNN和GCN提取），一个文本数据（使用FFN提取数据）。\nPathomicFusion\n","externalUrl":null,"permalink":"/paperreading/others/gated-attention/","section":"Paper Reading","summary":"","title":"GATED MULTIMODAL UNITS FOR INFORMATION FUSION","type":"paperreading"},{"content":"记录一些Java学习笔记\n","externalUrl":null,"permalink":"/java/","section":"Java","summary":"","title":"Java","type":"java"},{"content":"","externalUrl":null,"permalink":"/tags/java/","section":"Tags","summary":"","title":"Java","type":"tags"},{"content":"","externalUrl":null,"permalink":"/java/javaweb/","section":"Java","summary":"","title":"JavaWeb","type":"java"},{"content":"","externalUrl":null,"permalink":"/paperreading/mia/","section":"Paper Reading","summary":"","title":"MIA","type":"paperreading"},{"content":"","externalUrl":null,"permalink":"/tags/pooling/","section":"Tags","summary":"","title":"Pooling","type":"tags"},{"content":"金字塔池化模块（Pyramid Pooling Module，PPM）于 2017 年提出\n目的 # 为了聚合不同区域的上下文信息，以提高网络获取全局信息的能力\n实现 # 使用不同尺度的池化得到不同尺寸的特征图，再将这些特征图经过相应的采样后在通道维度上进行拼接，得到一个通道数更高的特征图，该特征图融合了不同尺度的信息，从而可以达到兼顾全局语义信息与局部细节信息的目的。\n网络结构图 # PyramidPooling\n(a) 输入图片； (b)通过 CNN 提取的原始特征图 (6 × 6 )； (c)PPM 模块：对原始特征图进行不同尺度的池化操作，得到多个不同尺寸的特征图（图中为 4 个）。对得到的特征图进行上采样操作，恢复至原始特征图大小 (6 × 6)，最后在通道维度上进行拼接，得到最终的复合特征图；\n红：使用 (6 × 6 ) 的池化，输出尺寸为 (1 × 1 ) ，再通过双线性插值上采样至 (6 × 6)； 橙：使用 (3 × 3) 的池化，输出尺寸为 (2 × 2 ) ，再通过双线性插值上采样至 (6 × 6)； 蓝：使用 (2 × 2 ) 的池化，输出尺寸为 (3 × 3) ，再通过双线性插值上采样至 (6 × 6)； 绿：使用 (1 × 1 ) 的池化，输出尺寸为 (6 × 6) 。\n代码实现 # import torch import torch.nn as nn import torch.nn.functional as F class PPM(nn.Module): def __init__(self, in_dim, out_dim, bins): super(PPM, self).__init__() self.features = [] for bin in bins: self.features.append(nn.Sequential( nn.AdaptiveAvgPool2d(bin), nn.Conv2d(in_dim, out_dim, kernel_size=1, bias=False), nn.BatchNorm2d(out_dim), nn.ReLU(inplace=True) )) self.features = nn.ModuleList(self.features) def forward(self, x): x_size = x.size() out = [x] for f in self.features: temp = f(x) temp = F.interpolate(temp, x_size[2:], mode=\u0026#34;bilinear\u0026#34;, align_corners=True) out.append(temp) return torch.cat(out, 1) if __name__ == \u0026#34;__main__\u0026#34;: # inputs: (B, C, H, W) inputs = torch.rand((8, 3, 16, 16)) # PPM params: (in_dim, out_dim, sizeList) ppm = PPM(3, 2, [1, 2, 3, 6]) # outputs: (B=8, C=3+2*4=11, H=16, W=16) outputs = ppm(inputs) print(\u0026#34;Outputs shape:\u0026#34;, outputs.size()) ","externalUrl":null,"permalink":"/paperreading/others/pyramid-pooling-module/","section":"Paper Reading","summary":"","title":"Pyramid Pooling Module","type":"paperreading"},{"content":" randaugment就是每次batch加载的时候都采用随机的数据增强，可以自己选择数据增强的数量。目的是为了实现数据的多样化，减少模型的过拟合，增加其泛化性以及鲁棒性。\n就是在数据处理的transform代码中插入随机数据增强，从而实现上述功能。\n","externalUrl":null,"permalink":"/paperreading/cvpr/randaugment/","section":"Paper Reading","summary":"","title":"RandAugment","type":"paperreading"},{"content":" 是一张关于CFP和OCT多模态分类的网络，采用了传统的提特征、对齐、融合的阶段。\n第一步提特征就采用正常的transformer。\n第二步借鉴了ALBEF和MOCOV3的方法，算是结合。对于编码器有两个子编码器对应transform1的Encoder q和 Encoder k，对于动量编码器也是两个编码器对应transform2的Encoder q和 Encoder k，都能提取CFP和OCT的特征，然后进行ctr loss的计算。\n作者规定了计算方式：\n把ALBEF的图拿过来更容易理解编码器、动量编码器的设置和其前向传播和计算方法，如下图：\nALBEF是图像输入和文本输入，而该文是两个图像输入。\n第三步是进行特征融合，在特征融合之前会先对OCT特征进行平均，然后与原来的特征进行contact拼接，再进入transformer进行特征的融合，最后只取最后一层最上方的特征来与CFP进行融合。\n融合包含两个阶段：\n1.两个特征contact直接进transformer块进行融合得到新特征\n2.将特征分开，CFP作为q，OCT作为k，v来进行更进一步的特征融合\n最后将融合后的特征再次contact送入MLP层进行分类。\n","externalUrl":null,"permalink":"/paperreading/miccai/mm-raf/","section":"Paper Reading","summary":"","title":"Representation, Alignment, Fusion: A Generic Transformer-Based Framework for Multi-modal Glaucoma Recognition","type":"paperreading"},{"content":"","externalUrl":null,"permalink":"/tags/semi/","section":"Tags","summary":"","title":"Semi","type":"tags"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":" PaperReading # 《UNIC: Universal Classification Models via Multi-teacher Distillation》 《MarginDistillation: distillation for margin-based softmax》 《AM-RADIO: Agglomerative Vision Foundation Model Reduce All Domains Into One》 《RADIOv2.5: Improved Baselines for Agglomerative Vision Foundation Models》 《Deep Mutual Distillation for Semi-supervised Medical Image Segmentation》 《AdaDistill: Adaptive Knowledge Distillation for Deep Face Recognition》 《Distilling Knowledge from Large-Scale Image Models for Object Detection》 《Good Teachers Explain: Explanation-Enhanced Knowledge Distillation》 《Simple Unsupervised Knowledge Distillation With Space Similarity》 2025 每周记录 # 2025.05.12-2025.05.18 # 修改完成论文 阅读3+KD论文 谷粒商城基础篇完结 + 高级篇部分 下载老师发的论文 2025.04.21-2025.04.27 # 整理Face相关的loss论文和代码笔记 《UNIC: Universal Classification Models via Multi-teacher Distillation》 看完计算机网络 论文格式修改 其它KD相关，暂定 2025.02.10-2025.02.16 # 这周啥科研都没做，学了一些Java基础相关的东西\nJavaSE 实验挂一下 Some Tricks # 2024 每周记录 # 2024.11.18-2024.11.24 # 摆！ 烂！ 了！ ！ 2024.7.08-7.14 # 这周估计做的事情比较少，懒惰懈怠愚蠢\n《All Tokens Matter: Token Labeling for Training Better Vision Transformers》 数据增强的方法 在新的dataset上测试一下效果 二叉树1-14 《QUADTREE ATTENTION FOR VISION TRANSFORMERS》 Transformer Interpretability Beyond Attention Visualization 2024.7.01-7.07 # 《SHaRPose: Sparse High-Resolution Representation for Human Pose Estimation》 《CF-ViT: A General Coarse-to-Fine Method for Vision Transformer》 《LF-ViT: Reducing Spatial Redundancy in Vision Transformer for Efficient Image Recognition》 CF-ViT和LF-ViT的代码 动态规划结束 调通CF-ViT和LF-ViT，做个小实验看看 2024.6.24-6.30 # 放假回家 coding了一个model，不收敛 下了imagenet和mini imagenet 2024.6.17-6.23 # 毕业典礼 组会汇报 琢磨transformer稀疏化 尝试多卡训练提升训练速度 找一篇论文看 动态规划11-21 2024.6.10-6.16 # 玩耍 2024.6.03-6.09 # 手敲贪心算法 动态规划1-10 《DTMFormer: Dynamic Token Merging for Boosting Transformer-Based Medical Image Segmentation》论文+代码 跑点无预训练权重的实验 本科毕业表 英语课PPT 2024.5.27-6.02 # 手敲回溯算法 MySQL基础语句 贪心算法1-10 上周的《MICA: Towards Explainable Skin Lesion Diagnosis via Multi-Level Image-Concept Alignment》 《Discrepancy and Gradient-Guided Multi-modal Knowledge Distillation for Pathological Glioma Grading》的代码 《ViT-Calibrator: Decision Stream Calibration for Vision Transformer》 《HACDR-Net: Heterogeneous-Aware Convolutional Network for Diabetic Retinopathy Multi-Lesion Segmentation》（看了，但没懂，代码也没开源） 2024.5.20-5.26 # 《Bi-directional Adapter for Multi-modal Tracking》 《Discrepancy and Gradient-Guided Multi-modal Knowledge Distillation for Pathological Glioma Grading》 《Comprehensive learning and adaptive teaching: Distilling multi-modal knowledge for pathological glioma grading》 《Learning Generalized Medical Image Segmentation from Decoupled Feature Queries》 《MICA: Towards Explainable Skin Lesion Diagnosis via Multi-Level Image-Concept Alignment》 回溯算法1-10 2.1经典召回模型 ","externalUrl":null,"permalink":"/notes/todo/","section":"Notes","summary":"","title":"TODO","type":"notes"},{"content":"对VIT的中的注意力机制进行魔改，没有采用先打成固定patch块并加入位置信息拉直后再送入网络中，而是采用先使用Depthwise Convolution深度可分离卷积（将卷积分为两步进行，但该文章code中只采用了第一步的深度卷积，而没有使用第二步的逐点卷积）进行特征提取（文中说这个就可以直接有位置信息了，我也不懂为什么，后续再进行了解）。除了原始的token外，采用了所谓的super token。super token就是对前面产生的特征先进行F.adaptive avg pool2d，意思就是先进行自适应的平均池化获得patch块，这个得到的token称为super token。\nStem模块就是常用的特征提取，包括卷积、归一化、激活函数的叠加。\n对于STT Block，由三个模块组成，分别为CPE,STA和ConvFFN。\nCPE模块就是最开始提到的特征提取模块，采用深度可分离卷积进行特征提取和位置信息的标注。\n#文中的深度可分离卷积（使用残差块） class ResDWC(nn.Module): def __init__(self, dim, kernel_size=3): super().__init__() self.dim = dim self.kernel_size = kernel_size self.conv = nn.Conv2d(dim, dim, kernel_size, 1, kernel_size//2, groups=dim) # self.conv_constant = nn.Parameter(torch.eye(kernel_size).reshape(dim, 1, kernel_size, kernel_size)) # self.conv_constant.requires_grad = False def forward(self, x): # return F.conv2d(x, self.conv.weight+self.conv_constant, self.conv.bias, stride=1, padding=self.kernel_size//2, groups=self.dim) # equal to x + conv(x) return x + self.conv(x) 在STA模块中，通过soft k-mean来得到token和super token之间的关系，以矩阵Q表示，公式如下：\n其中，X为Token，S为Super Token，本质就是做一个softmax计算其相似度。通过迭代公式19、20的计算，更新S和Q，不过文中只进行了一次迭代。\n在STS完成后，将得到的super token送入多头注意力机制得到新的Q特征，再进行一步所谓的token upsample（本质就是卷积调整维度，加上reshape函数调整其shape）来使得得到的特征和token的维度一致，然后使用新的Q来和这个特征进行矩阵计算得到新的X，作者说是从super token恢复到能表示图像的视觉token\n","externalUrl":null,"permalink":"/paperreading/cvpr/svit/","section":"Paper Reading","summary":"","title":"Vision Transformer with Super Token Sampling","type":"paperreading"},{"content":"","externalUrl":null,"permalink":"/java/algorithm_java/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/","section":"Java","summary":"","title":"代码随想录","type":"java"},{"content":"","externalUrl":null,"permalink":"/python/algorithm/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/","section":"Python","summary":"","title":"代码随想录","type":"python"},{"content":" 哈希 # 两数之和 # 链接\n力扣的第一题，梦开始的地方。\n第一次遇到一般都是简朴的想法，直接两层for循环遍历数组，寻找nums[i]+nums[j]==target，计算复杂度为n^2。\n利用空间换时间，定义一个hashmap: dict()，用于存储遍历过的元素则可只需要遍历一遍数组就可以实现要求。\nclass Solution: def twoSum(self, nums: List[int], target: int) -\u0026gt; List[int]: hashmap = dict() for i, num in enumerate(nums): if target - num not in hashmap: hashmap[num] = i else: return [i,hashmap[target - num]] 注意：dict查询操作为O(1)复杂度\n字母异位词分组 # 链接\n两种方法可以AC这题，但都需要使用hashmap。\n一种是直接对字符串进行排序，把排序后的字符串当作key，原字符串组成的list当作value；\nclass Solution: def groupAnagrams(self, strs: List[str]) -\u0026gt; List[List[str]]: d = defaultdict(list) for s in strs: d[\u0026#39;\u0026#39;.join(sorted(s))].append(s) # sorted(s) 相同的字符串分到同一组 return list(d.values()) 另外一种是对字符串出现的各个字母进行计数（需要转换到对应的ASCII），计数相同的则为一组，计数作为key，原字符串作为value。\nclass Solution: def groupAnagrams(self, strs: List[str]) -\u0026gt; List[List[str]]: record = defaultdict(list) for s in strs: count = [0] * 26 for letter in s: count[ord(letter) - ord(\u0026#39;a\u0026#39;)] += 1 record[tuple(count)].append(s) print(record) return list(record.values()) 最长连续序列 # 链接\n题目只需要返回最长连续序列的长度，并且要求O(n)的复杂度实现，因此考虑先对数组进行去重操作，即转换为set()。\n(set是无序的、不重复的，不可以进行索引)\n转换完成后，即可进行连续序列开头的寻找。对set进行遍历，如果x-1在set中则说明x不为开头元素，就不可能是最长连续序列的开头；如果x-1不在set中，则x作为开头元素，去判断x+1，x+2等是否在set中，此时使用变量进行记录，即可得到该x对应的最长连续序列。最终，对结果取max即可。\nclass Solution: def longestConsecutive(self, nums: List[int]) -\u0026gt; int: max_result = 0 nums = set(nums) for num in nums: if num - 1 in nums: continue else: current_num = num current_result = 1 while current_num + 1 in nums: current_num += 1 current_result += 1 max_result = max(max_result, current_result) return max_result 注意：List的查找是O(n),Set则为O(1)，Set是基于哈希表实现的。\n双指针 # 移动零 # 链接\n题目要求原地操作，因此只能使用双指针进行元素交换。\n定义两个指针i和j，i用于遍历数组，j始终指向0，如果i对应的数不为0，则与j元素进行交换，同时j+1。\n与快排相似，此处是将不是0的移到左边，是0的移到右边。\nclass Solution: def moveZeroes(self, nums: List[int]) -\u0026gt; None: \u0026#34;\u0026#34;\u0026#34; Do not return anything, modify nums in-place instead. \u0026#34;\u0026#34;\u0026#34; j = 0 for i in range(len(nums)): if nums[i] != 0: nums[i], nums[j] = nums[j], nums[i] j += 1 盛最多水的容器 # 链接\n贪心算法和双指针的一题，通过定义左右指针指向左边，去不断寻求该区间的最大值，从而得到全局最优解。\nclass Solution: def maxArea(self, height: List[int]) -\u0026gt; int: left = 0 right = len(height) - 1 result = 0 for i in range(len(height)): if height[left] \u0026lt; height[right]: result = max(result, (right-left)*height[left]) left += 1 else: result = max(result, (right-left)*height[right]) right -= 1 return result 三数之和 # 链接\n和二数之和不一样，二数之和是用hashmap来存储已经遍历的数据，从而降低计算复杂度。但三数之和需要进行去重处理，hashmap不能方便地进行处理，因此考虑使用双指针进行求解。\n双指针法通过对数组排序，配合双指针遍历，能够在 O(n^2) 的时间复杂度下有效地找到所有符合条件的三元组。\n先对数组进行排序。\n对于每个固定的数 nums[i]，用两个指针分别指向剩余数组的开头和末尾（即 left 和 right），通过检查三数之和来决定指针的移动。\n如果三数之和大于 0，说明右边的数太大，移动右指针向左。如果三数之和小于 0，说明左边的数太小，移动左指针向右。如果三数之和等于 0，记录这个三元组，并继续移动两个指针（跳过重复元素），确保不会有重复解。\nclass Solution: def threeSum(self, nums: List[int]) -\u0026gt; List[List[int]]: nums = sorted(nums) length = len(nums) result = [] for i in range(length): if i \u0026gt; 0 and nums[i] == nums[i-1]: continue left = i+1 right = length - 1 while left \u0026lt; right: if nums[i]+nums[left]+nums[right] \u0026lt; 0: left += 1 elif nums[i]+nums[left]+nums[right] \u0026gt; 0: right -= 1 else: result.append([nums[i],nums[left],nums[right]]) while left \u0026lt; length - 1 and nums[left] == nums[left+1]: left += 1 while right \u0026gt; i+1 and nums[right] == nums[right-1]: right -= 1 left += 1 right -= 1 return result 其实就是先选定一个元素（即遍历时用i表示），然后用两个指针去不断逼近答案。\n接雨水 # 链接\n该题有三种解法，分别为动态规划、单调栈和双指针，时间复杂度均为On，双指针的空间复杂度为O1。\n动态规划\n使用for循环遍历height的同时利用两个list去存储前序最大值和后序最大值，再使用一次for循环遍历height，此时计算可以接到的雨水量。\nclass Solution: def trap(self, height: List[int]) -\u0026gt; int: if not height: return 0 length = len(height) left_max = [height[0]] + [0] * (length - 1) for i in range(1, length): left_max[i] = max(left_max[i-1], height[i]) right_max = [0] * (length - 1) + [height[-1]] for j in range(length-2, -1, -1): right_max[j] = max(right_max[j+1], height[j]) res = 0 for k in range(length): res += (min(left_max[k], right_max[k]) - height[k]) return res 单调栈\n双指针\n滑动窗口 # ","externalUrl":null,"permalink":"/python/algorithm/hot100/hot100/","section":"Python","summary":"","title":"力扣Hot100","type":"python"},{"content":" 哈利表 # 1.两数之和 # 使用字典来存储已经遍历过的数据\nclass Solution: def twoSum(self, nums: List[int], target: int) -\u0026gt; List[int]: records = dict() for index, value in enumerate(nums): if target - value in records: return [records[target- value], index] records[value] = index return [] ","externalUrl":null,"permalink":"/python/algorithm/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/%E5%93%88%E5%B8%8C%E8%A1%A8/","section":"Python","summary":"","title":"哈希表","type":"python"},{"content":" 冒泡排序 # 比较相邻的元素，如果第一个比第二个大，就交换。\ndef bubble_sort(arr): n = len(arr) for i in range(n): for j in range(0, n-i-1): if arr[j] \u0026gt; arr[j+1]: arr[j], arr[j+1] = arr[j+1], arr[j] return arr 选择排序 # 选择排序非常直观，先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。\ndef selection_sort(arr): n = len(arr) for i in range(n): min_index = i for j in range(i+1, n): if arr[j] \u0026lt; arr[min_index]: min_index = j arr[i], arr[min_index] = arr[min_index], arr[i] print(arr) return arr 插入排序 # 插入排序也是一种直观的排序方式，原理是构建有序序列，从第二个元素开始，逐个和前面的元素（已排序）进行比较直到找到插入的位置。\ndef insertion_sort(arr): n = len(arr) for i in range(1, n): key = arr[i] j = i - 1 while j \u0026gt;= 0 and key \u0026lt; arr[j]: arr[j+1] = arr[j] j -= 1 arr[j+1] = key return arr 快速排序 # 使用递归进行排序，设置一个基准，将数据分成两部分，一部分数据小于基准，一部分大于，相同的可以在任意一边。\ndef quick_sort(arr): if len(arr) \u0026lt;= 1: return arr pivot = arr[len(arr) // 2] left = [x for x in arr if x \u0026lt; pivot] middle = [x for x in arr if x == pivot] right = [x for x in arr if x \u0026gt; pivot] return quick_sort(left) + middle + quick_sort(right) 排序算法效率比较 # 排序方法 平均情况 最好情况 最坏情况 辅助空间 稳定性 冒泡排序 $ O(n^2) $ $O(n)$ $O(n^2)$ $O(1)$ 稳定 选择排序 $O(n^2)$ $O(n^2)$ $O(n^2)$ $O(1)$ 不稳定 插入排序 $O(n^2)$ $O(n)$ $O(n^2)$ $O(1)$ 稳定 希尔排序 $O(n \\log n)$ ～ $O(n^2)$ $O(n^{1.3})$ $O(n^2)$ $O(1)$ 不稳定 堆排序 $O(n \\log n)$ $O(n \\log n)$ $O(n \\log n)$ $O(1)$ 不稳定 归并排序 $O(n \\log n)$ $O(n \\log n)$ $O(n \\log n)$ $O(n)$ 稳定 快速排序 $O(n \\log n)$ $O(n \\log n)$ $O(n^2)$ $O(log n)$ ～$O(n)$ 不稳定 ","externalUrl":null,"permalink":"/python/algorithm/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/%E6%8E%92%E5%BA%8F/","section":"Python","summary":"","title":"排序算法","type":"python"},{"content":" 1.二分查找 # 对于有序数组就可以考虑使用二分法\n704.二分查找 # 力扣链接\n本题list是有序的，所以可以根据left，right，middle来进行查找，不符合条件的区间直接pass，从而大大减少时间复杂度\n35. 搜索插入位置 # 力扣链接\n34. 在排序数组中查找元素的第一个和最后一个位置 # 力扣链接\n69. x的平方根 # 力扣链接\n367.有效的完全平方数(opens new window) # 力扣链接\n2.移除元素 # 27.移除元素 # 力扣链接\n26.删除排序数组中的重复项 # 力扣链接\n283.移动零 # 力扣链接\n844.比较含退格的字符串 # 力扣链接\n3.有序数组的平方 # 977.有序数组的平方 # 力扣链接\n4.长度最小的子数组 # 209.长度最小的子数组 # 力扣链接\n904.水果成篮 # 力扣链接\n76.最小覆盖子串 # 力扣链接\n5.螺旋矩阵II # 59.螺旋矩阵II # 力扣链接\n54.螺旋矩阵 # 力扣链接\nLCR146.螺旋遍历二维数组 # 力扣链接\n","externalUrl":null,"permalink":"/java/algorithm_java/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/01%E6%95%B0%E7%BB%84/","section":"Java","summary":"","title":"数组","type":"java"},{"content":" 1.二分查找 # 对于有序数组就可以考虑使用二分法\n704.二分查找 # 力扣链接\n本题list是有序的，所以可以根据left，right，middle来进行查找，不符合条件的区间直接pass，从而大大减少时间复杂度\nclass Solution: def search(self, nums: List[int], target: int) -\u0026gt; int: left, right = 0, len(nums) - 1 while left \u0026lt;= right: middle = left + (right - left) // 2 if nums[middle] \u0026gt; target: right = middle - 1 elif nums[middle] \u0026lt; target: left = middle + 1 else: return middle return -1 时间复杂度为：$ O(log n) $\n空间复杂度为：$ O(1) $\n35. 搜索插入位置 # 力扣链接\n34. 在排序数组中查找元素的第一个和最后一个位置 # 力扣链接\n69. x的平方根 # 力扣链接\n367.有效的完全平方数(opens new window) # 力扣链接\n2.移除元素 # 27.移除元素 # 力扣链接\n26.删除排序数组中的重复项 # 力扣链接\n283.移动零 # 力扣链接\n844.比较含退格的字符串 # 力扣链接\n3.有序数组的平方 # 977.有序数组的平方 # 力扣链接\n4.长度最小的子数组 # 209.长度最小的子数组 # 力扣链接\n904.水果成篮 # 力扣链接\n76.最小覆盖子串 # 力扣链接\n5.螺旋矩阵II # 59.螺旋矩阵II # 力扣链接\n54.螺旋矩阵 # 力扣链接\nLCR146.螺旋遍历二维数组 # 力扣链接\n","externalUrl":null,"permalink":"/python/algorithm/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/%E6%95%B0%E7%BB%84/","section":"Python","summary":"","title":"数组","type":"python"},{"content":" HashMap # 创建 HashMap\nMap\u0026lt;Integer, Integer\u0026gt; hashMap = new HashMap\u0026lt;\u0026gt;(); 在 Java 中，HashMap\u0026lt;K, V\u0026gt; 是无序的，经常需要按 Key 或 Value 进行排序。\n按照key排序\n使用 TreeMap 直接排序 Map\u0026lt;Integer, Integer\u0026gt; sortedMap = new TreeMap\u0026lt;\u0026gt;(hashMap); 使用 Comparator 和 List.sort() // 将 HashMap 转换为 List List\u0026lt;Map.Entry\u0026lt;Integer, String\u0026gt;\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(hashMap.entrySet()); // 按 Key 升序排序 list.sort(Comparator.comparingInt(Map.Entry::getKey)); 按 Key 降序 list.sort(Comparator.comparingInt(Map.Entry::getKey).reversed()); 按照Value排序\nHashMap 默认按 Key 查找，可以使用 Comparator 按 Value 排序。\n按 Value 升序 // 转换为 List List\u0026lt;Map.Entry\u0026lt;String, Integer\u0026gt;\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(hashMap.entrySet()); // 按 Value 升序排序 list.sort(Comparator.comparingInt(Map.Entry::getValue)); 按 Value 降序 list.sort(Comparator.comparingInt(Map.Entry::getValue).reversed()); HashMap 结合 PriorityQueue（堆排序）\n用 PriorityQueue 找出 Value 最大的前 K 个元素 // 小顶堆，按 Value 升序排序 PriorityQueue\u0026lt;Map.Entry\u0026lt;String, Integer\u0026gt;\u0026gt; minHeap = new PriorityQueue\u0026lt;\u0026gt;(Comparator.comparingInt(Map.Entry::getValue)); // 遍历 HashMap，加入堆 for (Map.Entry\u0026lt;String, Integer\u0026gt; entry : freqMap.entrySet()) { minHeap.offer(entry); if (minHeap.size() \u0026gt; k) { minHeap.poll(); // 只保留最大的 K 个 } } // 输出前 K 个最大值 while (!minHeap.isEmpty()) { System.out.println(minHeap.poll()); } 用 PriorityQueue 构造「大顶堆」按 Value 降序排列 PriorityQueue\u0026lt;Map.Entry\u0026lt;String, Integer\u0026gt;\u0026gt; maxHeap = new PriorityQueue\u0026lt;\u0026gt;(Collections.reverseOrder(Comparator.comparingInt(Map.Entry::getValue))); maxHeap.addAll(freqMap.entrySet()); while (!maxHeap.isEmpty()) { System.out.println(maxHeap.poll()); } 栈与队列 # 在Java中，可以使用ArrayDeque作为栈、队列、双端队列使用，可以使用双端队列通用的api以避免混淆。\n创建ArrayDeque\nDeque\u0026lt;Integer\u0026gt; deque = new ArrayDeque\u0026lt;\u0026gt;(); 操作 方法 栈 (Stack, LIFO) 队列 (Queue, FIFO) 双端队列 (Deque) 插入元素 offerFirst(E e) ✅ (push) ❌ ✅ (前端) offerLast(E e) ❌ ✅ (offer) ✅ (后端) 获取元素 peekFirst() ✅ (peek) ✅ (队头) ✅ (前端) peekLast() ❌ ❌ ✅ (后端) 删除元素 pollFirst() ✅ (pop) ✅ (poll) ✅ (前端) pollLast() ❌ ❌ ✅ (后端) 检查状态 isEmpty() ✅ ✅ ✅ size() ✅ ✅ ✅ 顺序结构 # Java读取单个字符时，一般使用char c = scanner.next().charAt(0);\n不能使用char进行强制转换char c = (char) scanner.next();\n``scanner.next()`读取的是String\n对于字符串的字母转换(小\u0026ndash;\u0026gt;大)有两种方法，一是使用Character char upper = Character.toUpperCase(lower)，\n二是使用 char upper = (char) (lower - 32)\n大 \u0026mdash;\u0026gt;小时，就是Upper变Lower，-变+\nJava中关于字符串转换和翻转的一些操作。使用 String s = String.valueOf(num);可以将数字转为字符串。\n对字符串进行翻转需要使用 StringBulider,即 String reversed = new StringBuilder(str).reverse().toString();注意需要将StringBuilder转换为String类型\n向上取整 ，对于整数可以使用int result = (a + b - 1) / b;\n对于浮点数使用 Math.ceil()\n默认的 /（floor division）是向下取整\n分支结构 # 辗转相除法可以注意一下\npublic static int gcd(int a, int b){ return b == 0 ? a : gcd(b, a%b); } 对数组进行排序使用 Arrays.sort(nums);\n判断字符是否为数字 Character.isDigit(ch\n获取字符串中指定位置的字符 str.charAt(i)\n循环结构 # int为32位，long为64位，如果需要更大的位数则需要使用 BigInteger,它可以处理任意大小的整数.\n下面为一个示例代码，用于计算阶乘和求和。当n过大时，则需要使用BigInteger.\nimport java.util.Scanner; import java.math.BigInteger; public class Main { public static void main(String[] args) { Scanner scanner = new Scanner(System.in); int n = scanner.nextInt(); BigInteger total = BigInteger.ZERO; // 使用 BigInteger 存储总和 while (n \u0026gt; 0) { total = total.add(fac(n)); // 使用 add 方法相加 n--; } System.out.println(total); } // 使用 BigInteger 计算阶乘 public static BigInteger fac(int n) { if (n == 1) return BigInteger.ONE; else return fac(n - 1).multiply(BigInteger.valueOf(n)); // 使用 multiply 方法相乘 } } 对于字符串，可以使用 String str = String.valueOf(i);将数字转为字符串；也可以使用 for (char c : str.toCharArray())将字符串转为char数组；还可以使用StringBuilder进行拼接。\nStringBuilder c = new StringBuilder(); for(int i = 1; i \u0026lt;= n; i++){ c.append(i); } 找到数组中的最大值：Java 8 及以后版本提供了 Arrays.stream() 方法，可以轻松地找到最大值和最小值。\nint max = Arrays.stream(arr).max().getAsInt(); int min = Arrays.stream(arr).min().getAsInt(); 数组 # List常用的为 ArrayList\u0026lt;Integer/int[]/String等等\u0026gt;\n对于一些需要去重和检查交集的情况，可以使用 HastSet,\nHashSet 是 Set 接口的一个具体实现，内部基于哈希表（HashMap）来存储元素。它不允许存储重复的元素，且不保证元素的顺序。\nretainAll(Collection\u0026lt;?\u0026gt; c) 方法是 Set 接口的一个方法，它用于保留当前集合和给定集合 c 的交集。即，调用该方法后，Set 集合中只会保留与集合 c 中相同的元素，其他元素将被移除。\n对于**Collection 类型**（如 ArrayList, LinkedList, HashSet, TreeSet 等），其可以使用很多Collection的方法，比如找最大最小值、排序、翻转等。\n方法 作用 min(Collection\u0026lt;T\u0026gt;) 获取最小值 max(Collection\u0026lt;T\u0026gt;) 获取最大值 sort(List\u0026lt;T\u0026gt;) 升序排序 sort(List\u0026lt;T\u0026gt;, Comparator\u0026lt;T\u0026gt;) 按自定义规则排序 reverse(List\u0026lt;T\u0026gt;) 反转列表 shuffle(List\u0026lt;T\u0026gt;) 随机打乱 binarySearch(List\u0026lt;T\u0026gt;, T key) 二分查找（前提：必须排序） fill(List\u0026lt;T\u0026gt;, T value) 用 value 填充整个列表 copy(List\u0026lt;T\u0026gt; dest, List\u0026lt;T\u0026gt; src) 复制 src 到 dest swap(List\u0026lt;T\u0026gt;, int i, int j) 交换 i 和 j 位置的元素 frequency(Collection\u0026lt;T\u0026gt;, T key) 统计 key 出现的次数 disjoint(Collection\u0026lt;T\u0026gt;, Collection\u0026lt;T\u0026gt;) 判断两个集合是否无交集 对于int[]这种基本数据类型数组，不能用Collection，可以使用 int minValue = Arrays.stream(nums).min().getAsInt();或者直接遍历寻找就行了。\n滑动窗口有两种方法，一种维护数组（用了前缀和）需要 O(N)的空间复杂度，一种不需要只需要 O(1)\n//前缀和版本 long[] sum = new long[n + 1]; sum[0] = 0; sum[1] = num[0]; for (int i = 1; i \u0026lt; n; i++) { sum[i + 1] = sum[i] + num[i]; } long minValue = Long.MAX_VALUE; for (int i = m; i \u0026lt;= n; i++) { long windowSum = sum[i] - sum[i - m]; minValue = Math.min(minValue, windowSum); } //只维护 windowSum 变量 int windowSum = 0; for (int i = 0; i \u0026lt; m; i++) { windowSum += num[i]; } int minSum = windowSum; for (int i = m; i \u0026lt; n; i++) { windowSum += num[i] - num[i - m]; minSum = Math.min(minSum, windowSum); } 使用BufferedReader读取数据，相对于Scanner更快，但需要自己处理数据。\nBufferedReader br = new BufferedReader(new InputStreamReader(System.in)); String[] str = br.readLine().split(\u0026#34; \u0026#34;); int m = Integer.parseInt(str[0]); int n = Integer.parseInt(str[1]); hashset读取数值\n蛇形方针、杨辉三角\n方块转换\n字符串 # line.split(\u0026quot;\\\\s+\u0026quot;)匹配一个或多个空白字符，以处理 多个连续的空格，或者不同类型的空白符，包括空格制表符 \\t、换行符 \\n 等；而line.split(\u0026quot; \u0026quot;)只是 普通的字符串，表示 严格匹配一个空格，但不会匹配多个连续的空格，也不会匹配 \\t 或 \\n。\n关于 ArrayList\u0026lt;Integer\u0026gt; nums = new ArrayList\u0026lt;\u0026gt;();，删除其中的某个元素：\n1.使用 nums.remove(索引);\n2.nums.remove(Integer.valueOf(目标值));但不能在 for-each 循环中直接修改 ArrayList 3.推荐使用 nums.removeIf(n -\u0026gt; 条件); nums.removeIf(n -\u0026gt; n == 2); // 删除所有 2\n函数与结构体 # 判断是否为质数\n//法1 boolean isPrime(int num) { if (num \u0026lt; 2) return false; for (int i = 2; i * i \u0026lt;= num; i++) { // 只检查 `2 ~ sqrt(N)` if (num % i == 0) return false; } return true; } //法2 埃拉托色尼筛法 private static void sieve(int limit) { // 1. 初始化所有数为“可能是质数” for (int i = 0; i \u0026lt;= limit; i++) isPrime[i] = true; // 2. 0 和 1 不是质数 isPrime[0] = isPrime[1] = false; // 3. 遍历所有数，并筛除它们的倍数 for (int i = 2; i * i \u0026lt;= limit; i++) { // 只检查到 sqrt(limit) if (isPrime[i]) { // i 是质数，则筛去 i 的倍数 for (int j = i * i; j \u0026lt;= limit; j += i) { // 从 i² 开始筛 isPrime[j] = false; } } } } 法2更加高效\n方法 时间复杂度 适用范围 暴力检查 O(N) O(N) 单个数 检查 2 ~ sqrt(N) O(√N) 单个数 埃拉托色尼筛法 O(N log log N) 批量判断（N ≤ 10^7） 公式：所有子集元素之和 $=(s_1 + s_2 + \\cdots + s_n) \\times 2^{n-1}=\\bigl(\\sum_{i=1}^{n} s_i\\bigr) \\times 2^{n-1}.$ BufferedReader、BufferedWriter # StringBuilder、StringBuffer # ","externalUrl":null,"permalink":"/java/algorithm_java/%E6%9D%82%E8%AE%B0/","section":"Java","summary":"","title":"杂记","type":"java"},{"content":" 一.读取通道为RGB # 1.PIL (Python Imaging Library) # from PIL import Image import numpy as np img = Image.open(\u0026#34;/path/image\u0026#34;) img = np.array(img) 2.matplotlib.image # import matplotlib.image as mpimg img = mpimg.imread(\u0026#34;/path/image\u0026#34;) 3.skimage.io # import skimage.io as io img = io.imread(\u0026#34;/path/image\u0026#34;) 4.matplotlib.pyplot # import matplotlib.pyplot as plt img = plt.imread(\u0026#34;/path/image\u0026#34;) 二.OPENCV读取通道为BGR # 此时如果直接使用plt进行显示，则会造成图像色彩失真\n1.使用cv2提供的BGR2RGB函数，最简单方便 # import matplotlib.pyplot as plt import cv2 img = cv2.imread(\u0026#34;/path/image\u0026#34;) img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) plt.imshow(img_rgb) plt.show() 2.使用cv2的merge函数手动合并通道 # import matplotlib.pyplot as plt import cv2 img = cv2.imread(\u0026#34;/path/image\u0026#34;) b, g, r = cv2.split(img) img_rgb = cv2.merge([r, g, b]) plt.imshow(img_rgb) plt.show() 3.使用矩阵的翻转 # import matplotlib.pyplot as plt import cv2 img = cv2.imread(\u0026#34;/path/image\u0026#34;) img_rgb = img[:,:,::-1] plt.imshow(img_rgb) plt.show() Image.open和transform后的维度问题 # Image.open不会改变图像的维度，会保持原始维度。\nplt.show传入的图像只能是HWC。如果采用img=Image.open(\u0026quot;./\u0026quot;)打开图像，则可以正常使用plt.show。\n而在我使用torchvision.transforms对图片进行处理后，plt.show不能正常显示图像，会报错。\n原因是在某个transform后图像的维度会发生改变，变成CHW。具体是因为transforms.ToTensor()会造成维度的变化，将C变为第一位。此时需要进行一定的维度转换，才能只能显示。代码如下：\nimg_transformed = train_transformer(img) img_transformed_np = np.transpose(np.array(img_transformed), (1, 2, 0)) 使用该代码使得图像的维度变成HWC，从而可以正常显示图像。\n如果不使用ToTensor()则不需要进行维度转换，其图像为正常图像，可以直接plt.show()\n","externalUrl":null,"permalink":"/python/imageprocessing/%E8%AF%BB%E5%8F%96%E5%9B%BE%E5%83%8F%E5%B9%B6%E6%98%BE%E7%A4%BA/%E8%AF%BB%E5%8F%96%E5%9B%BE%E5%83%8F%E5%B9%B6%E6%98%BE%E7%A4%BA%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/","section":"Python","summary":"","title":"读取图像并显示的几种方法","type":"python"},{"content":"","externalUrl":null,"permalink":"/python/algorithm/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/%E9%93%BE%E8%A1%A8/","section":"Python","summary":"","title":"链表","type":"python"}]